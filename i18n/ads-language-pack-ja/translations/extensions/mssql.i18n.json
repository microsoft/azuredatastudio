{
	"": [
		"--------------------------------------------------------------------------------------------",
		"Copyright (c) Microsoft Corporation. All rights reserved.",
		"Licensed under the Source EULA. See License.txt in the project root for license information.",
		"--------------------------------------------------------------------------------------------",
		"Do not edit this file. It is machine generated."
	],
	"version": "1.0.0",
	"contents": {
		"dist/dashboard/serviceEndpoints": {
			"copyText": "コピー",
			"endpoint.appproxy": "アプリケーション プロキシ",
			"endpoint.controller": "クラスター管理サービス",
			"endpoint.gateway": "HDFS ファイルにアクセスするためのゲートウェイ、Spark",
			"endpoint.grafana": "メトリック ダッシュボード",
			"endpoint.kibana": "ログ検索ダッシュボード",
			"endpoint.livy": "Spark ステートメント、ジョブ、アプリケーションを実行するためのプロキシ",
			"endpoint.managementproxy": "管理プロキシ",
			"endpoint.mgmtproxy": "管理プロキシ",
			"endpoint.sparkHistory": "Spark ジョブの管理と監視ダッシュボード",
			"endpoint.sqlServerEndpoint": "SQL Server マスター インスタンス フロントエンド",
			"endpoint.webhdfs": "HDFS ファイル システム プロキシ",
			"endpoint.yarnHistory": "Spark 診断と監視ダッシュボード",
			"grafana": "メトリック ダッシュボード",
			"kibana": "ログ検索ダッシュボード",
			"sparkHistory": "Spark ジョブの管理と監視ダッシュボード",
			"yarnHistory": "Spark 診断と監視ダッシュボード"
		},
		"dist/features": {
			"mssql.canceledLinkedAzureAccountSelection": "Azure Data Studio では、Always Encrypted の列マスター キーにアクセスするために Azure Key Vault に接続する必要がありますが、リンクされた Azure アカウントが選択されていません。クエリを再試行して、メッセージが表示されたら、リンクされた Azure アカウントを選択してください。",
			"mssql.chooseLinkedAzureAccount": "リンクされた Azure アカウントを選択してください:",
			"mssql.insufficientlyPrivelagedAzureAccount": "{0} に構成された Azure アカウントには、Always Encrypted の列マスターキーにアクセスするための Azure Key Vault の十分なアクセス許可がありません。",
			"mssql.missingLinkedAzureAccount": "Azure Data Studio では、Always Encrypted の列マスター キーにアクセスするために Azure Key Vault に接続する必要がありますが、リンクされた Azure アカウントがありません。リンクされた Azure アカウントを追加して、クエリを再試行してください。"
		},
		"dist/hdfs/hdfsModel": {
			"mssql.recursivePermissionOpError": "アクセス許可の変更の適用でエラーが発生しました: {0}",
			"mssql.recursivePermissionOpProgress": "アクセス許可の変更を '{0}' に適用しています。",
			"mssql.recursivePermissionOpStarted": "アクセス許可の変更を '{0}' に再帰的に適用しています",
			"mssql.recursivePermissionOpSucceeded": "アクセス許可の変更が正常に適用されました。"
		},
		"dist/hdfs/webhdfs": {
			"webhdfs.httpError400": "無効な要求",
			"webhdfs.httpError401": "許可されていません",
			"webhdfs.httpError403": "禁止されています",
			"webhdfs.httpError404": "見つかりません",
			"webhdfs.httpError500": "内部サーバー エラー",
			"webhdfs.invalidDataStructure": "無効なデータ構造",
			"webhdfs.missingProperties": "オプションが不足しているため、WebHDFS クライアントを作成できません: ${0}",
			"webhdfs.undefinedArgument": "'${0}' は未定義です。",
			"webhdfs.unexpectedRedirect": "予期しないリダイレクト",
			"webhdfs.unknownError": "不明なエラー"
		},
		"dist/localizedConstants": {
			"msgMissingNodeContext": "ノードが渡されずに呼び出されたノード コマンド",
			"mssql.accessHeader": "アクセス",
			"mssql.addLabel": "追加",
			"mssql.addUserOrGroup": "ユーザーまたはグループの追加",
			"mssql.apply": "適用",
			"mssql.applyRecursively": "再帰的に適用",
			"mssql.defaultHeader": "既定",
			"mssql.defaultUserAndGroups": "既定のユーザーとグループ",
			"mssql.delete": "削除",
			"mssql.enterNamePlaceholder": "名前の入力",
			"mssql.errorApplyingAclChanges": "変更の適用中に予期しないエラーが発生しました: {0}",
			"mssql.everyone": "他のすべてのユーザー",
			"mssql.executeHeader": "実行",
			"mssql.group": "グループ",
			"mssql.groupLabel": "グループ",
			"mssql.inheritDefaultsLabel": "既定値の継承",
			"mssql.locationTitle": "場所: ",
			"mssql.manageAccessTitle": "アクセスの管理",
			"mssql.namedUsersAndGroups": "名前付きユーザーとグループ",
			"mssql.owner": "所有者",
			"mssql.ownerPostfix": " - 所有者",
			"mssql.owningGroupPostfix": " - 所有グループ",
			"mssql.permissionsTitle": "アクセス許可",
			"mssql.readHeader": "読み取り",
			"mssql.stickyHeader": "スティッキー ビット",
			"mssql.userLabel": "ユーザー",
			"mssql.userOrGroupIcon": "ユーザーまたはグループ アイコン",
			"mssql.writeHeader": "書き込み",
			"sparkConnectionRequired": "{0} 履歴を表示する前に、Spark クラスターに接続してください。",
			"sparkJobSubmission.GetApplicationIdFailed": "アプリケーション ID の取得に失敗しました。{0}",
			"sparkJobSubmission.LocalFileDestinationHint": "ローカル ファイルは HDFS にアップロードされます。 ",
			"sparkJobSubmission.LocalFileNotExisted": "ローカル ファイル {0} が存在しません。 ",
			"sparkJobSubmission.NoSqlBigDataClusterFound": "SQL Server ビッグ データ クラスターが見つかりません。",
			"sparkJobSubmission.PrepareSubmitJob": "ジョブ {0} を送信しています...",
			"sparkJobSubmission.PrepareUploadingFile": "ローカル {0} から HDFS フォルダーへファイルをアップロードしています: {1}",
			"sparkJobSubmission.SparkHistoryLinkMessage": "Spark 履歴 URL: {0} ",
			"sparkJobSubmission.SubmissionEndMessage": ".......................... Spark ジョブの送信終了 ............................",
			"sparkJobSubmission.SubmitJobFailed": "Spark ジョブを送信できませんでした。{0} ",
			"sparkJobSubmission.SubmitJobFinished": "Spark ジョブが送信されました。",
			"sparkJobSubmission.UploadingFileFailed": "ファイルをクラスターにアップロードできませんでした。{0}",
			"sparkJobSubmission.UploadingFileSucceeded": "ファイルがクラスターに正常にアップロードされました。",
			"sparkJobSubmission.YarnUIMessage": "YarnUI URL: {0} "
		},
		"dist/main": {
			"msgSampleCodeDataFrame": "このサンプル コードは、ファイルをデータ フレームに読み込み、最初の 10 件の結果を示します。",
			"mssql.errorConvertingToNotebook": "SQL ドキュメントをノートブックに変換中にエラーが発生しました。エラー: {0}",
			"mssql.errorConvertingToSQL": "ノートブック ドキュメントを SQL に変換中にエラーが発生しました。エラー: {0}",
			"noController": "このインスタンスのコントローラー エンドポイントが見つかりませんでした",
			"notebookFileType": "ノートブック",
			"unsupportedFileType": ".ipynb ノートブックのみがサポートされています"
		},
		"dist/objectExplorerNodeProvider/cancelableStream": {
			"streamCanceled": "ユーザーによって取り消されたストリーム操作"
		},
		"dist/objectExplorerNodeProvider/command": {
			"cancel": "操作をキャンセルしますか?",
			"cancelTooltip": "キャンセル",
			"mssql.searchServers": "サーバー名を検索",
			"progress": "$(sync~spin) {0}..."
		},
		"dist/objectExplorerNodeProvider/connection": {
			"connectionInfoOptionsMissingProperties": "connectionInfo.options で一部のプロパティが不足しています: {0}",
			"connectionInfoOptionsUndefined": "ConnectionInfo.options が定義されていません。",
			"connectionInfoUndefined": "ConnectionInfo が定義されていません。"
		},
		"dist/objectExplorerNodeProvider/fileSources": {
			"maxSizeNotice": "注意: このファイルはプレビュー用に {0} で切り詰められました。 ",
			"maxSizeReached": "ファイルはプレビュー用に {0} で切り捨てられました。"
		},
		"dist/objectExplorerNodeProvider/hdfsCommands": {
			"allFiles": "すべてのファイル",
			"copyPathError": "パスのコピーでエラーが発生しました: {0}",
			"deleteError": "ファイルの削除でエラーが発生しました: {0}",
			"enterDirName": "ディレクトリ名を入力する",
			"lblUploadFiles": "アップロード",
			"makingDir": "ディレクトリを作成しています",
			"manageAccessError": "[アクセスの管理] ダイアログを開いている間に予期しないエラーが発生しました: {0}",
			"mkDirError": "ディレクトリの作成でエラーが発生しました: {0}",
			"mkdirCanceled": "操作が取り消されました",
			"msgDeleteFile": "このファイルを削除しますか?",
			"msgDeleteFolder": "対象フォルダーとその内容を削除してもよろしいですか?",
			"previewError": "ファイルのプレビューでエラーが発生しました: {0}",
			"previewing": "プレビューを生成しています",
			"saveCanceled": "保存操作は取り消されました",
			"saveError": "ファイルの保存でエラーが発生しました: {0}",
			"saving": "HDFS ファイルを保存しています",
			"uploadCanceled": "アップロード操作が取り消されました",
			"uploadError": "ファイルのアップロードでエラーが発生しました: {0}",
			"uploading": "HDFS にファイルをアップロードしています"
		},
		"dist/objectExplorerNodeProvider/hdfsProvider": {
			"errDeleteConnectionNode": "接続を削除できません。削除できるのはサブフォルダーとファイルのみです。",
			"errorExpanding": "エラー: {0}"
		},
		"dist/objectExplorerNodeProvider/objectExplorerNodeProvider": {
			"hdfsFolder": "HDFS",
			"notifyError": "ノード変更の通知でエラーが発生しました: {0}",
			"prmptPwd": "HDFS に接続するためのパスワードを入力してください:",
			"promptUsername": "HDFS に接続するためのユーザー名を入力してください:",
			"rootLabel": "ルート",
			"sessionNotFound": "ノード {0} のセッションが存在しません"
		},
		"dist/prompts/confirm": {
			"msgNo": "いいえ",
			"msgYes": "はい"
		},
		"dist/sparkFeature/dialog/dialogCommands": {
			"errorNotSqlBigDataCluster": "選択したサーバーが SQL Server ビッグ データ クラスターに属していません",
			"selectOtherServer": "他の SQL Server を選択する",
			"sparkJobSubmission.GetFilePathFromSelectedNodeFailed": "ファイル パス取得エラー: {0}",
			"sparkJobSubmission.NoSqlSelected": "SQL Server が選択されていません。",
			"sparkJobSubmission.PleaseSelectSqlWithCluster": "ビッグ データ クラスターが含まれる SQL Server を選択してください。"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkAdvancedTab": {
			"sparkJobSubmission.AdvancedTabName": "詳細",
			"sparkJobSubmission.ReferenceFilesList": "参照ファイル",
			"sparkJobSubmission.ReferenceFilesListTooltip": "Executor 作業ディレクトリに配置されるファイル。ファイル パスは HDFS パスにする必要があります。複数のパスはセミコロン (;) で区切ってください",
			"sparkJobSubmission.ReferenceJarList": "Jar を参照する",
			"sparkJobSubmission.ReferenceJarListToolTip": "Executor 作業ディレクトリに配置される Jar。Jar パスは HDFS パスにする必要があります。複数のパスはセミコロン (;) で区切ってください",
			"sparkJobSubmission.ReferencePyList": "参照 py ファイル",
			"sparkJobSubmission.ReferencePyListTooltip": "Executor 作業ディレクトリに配置される Py ファイル。ファイル パスは HDFS パスにする必要があります。複数のパスはセミコロン (;) で区切ってください",
			"sparkJobSubmission.configValues": "構成値",
			"sparkJobSubmission.configValuesTooltip": "Spark 構成値を含む名前値ペアの一覧。JSON 辞書としてエンコードされます。例: '{\"name\":\"value\", \"name2\":\"value2\"}'。",
			"sparkJobSubmission.driverCores": "ドライバー コア",
			"sparkJobSubmission.driverCoresTooltip": "ドライバーに割り当てる CPU コアの量。",
			"sparkJobSubmission.driverMemory": "ドライバーのメモリ",
			"sparkJobSubmission.driverMemoryTooltip": "ドライバーに割り当てるメモリの量。値の一部として単位を指定します。たとえば 512 M や 2 G などです。",
			"sparkJobSubmission.executorCores": "Executor のコア",
			"sparkJobSubmission.executorCoresTooltip": "Executor に割り当てる CPU コアの量。",
			"sparkJobSubmission.executorCount": "Executor の数",
			"sparkJobSubmission.executorCountTooltip": "実行する Executor のインスタンスの数。",
			"sparkJobSubmission.executorMemory": "Executor のメモリ",
			"sparkJobSubmission.executorMemoryTooltip": "Executor に割り当てるメモリの量。値の一部として単位を指定します。たとえば 512 M や 2 G などです。",
			"sparkJobSubmission.queueName": "キュー名",
			"sparkJobSubmission.queueNameTooltip": "セッションを実行する Spark キューの名前。"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkConfigurationTab": {
			"sparkJobSubmission.Arguments": "引数",
			"sparkJobSubmission.ArgumentsTooltip": "メイン クラスで使用されるコマンド ライン引数。複数の引数を使うには、スペースで区切る必要があります。",
			"sparkJobSubmission.FilePathPlaceHolder": ".jar ファイルまたは .py ファイルへのパス",
			"sparkJobSubmission.GeneralTabName": "全般",
			"sparkJobSubmission.HDFSFileNotExisted": "指定された HDFS ファイルが存在しません。 ",
			"sparkJobSubmission.HDFSFileNotExistedWithPath": "{0} がクラスターに存在しないか、例外がスローされました。 ",
			"sparkJobSubmission.JobName": "ジョブ名",
			"sparkJobSubmission.JobNamePlaceHolder": "名前の入力...",
			"sparkJobSubmission.LocalFileDestinationHintWithPath": "選択したローカル ファイルが HDFS にアップロードされます: {0}",
			"sparkJobSubmission.MainClass": "メイン クラス",
			"sparkJobSubmission.MainFilePath": "JAR/py ファイル",
			"sparkJobSubmission.NotSpecifyJARPYPath": "プロパティ JAR/py ファイルが指定されていません。",
			"sparkJobSubmission.NotSpecifyJobName": "プロパティ ジョブ名が指定されていません。",
			"sparkJobSubmission.NotSpecifyMainClass": "プロパティ メイン クラスが指定されていません。",
			"sparkJobSubmission.SelectFileError": "次のエラーが原因で、ファイルの検索でエラーが発生しました: {0}",
			"sparkJobSubmission.SparkCluster": "Spark クラスター",
			"sparkSelectLocalFile": "選択"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionDialog": {
			"sparkJobSubmission.DialogCancelButton": "キャンセル",
			"sparkJobSubmission.DialogSubmitButton": "送信",
			"sparkJobSubmission.DialogTitleNewJob": "新しいジョブ",
			"sparkJobSubmission.SparkJobSubmissionDialogInitializeError": "SparkJobSubmissionDialog のパラメーターが無効です",
			"sparkJobSubmission.SubmissionStartMessage": ".......................... Spark ジョブの送信開始 ..........................",
			"sparkJobSubmission.SubmitSparkJob": "{0} Spark ジョブの送信:"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionModel": {
			"sparkJobSubmission.GetApplicationIdTimeOut": "アプリケーション ID の取得タイムアウト。{0}[ログ]   {1}",
			"sparkJobSubmission.LivyBatchIdIsInvalid": "livyBatchId が無効です。 ",
			"sparkJobSubmission.PathNotSpecified.": "プロパティ パスが指定されていません。 ",
			"sparkJobSubmission.SparkJobSubmissionModelInitializeError": "SparkJobSubmissionModel のパラメーターが無効です",
			"sparkJobSubmission.localFileOrFolderNotSpecified.": "プロパティ localFilePath または hdfsFolderPath が指定されていません。 ",
			"sparkJobSubmission.submissionArgsIsInvalid": "submissionArgs が無効です。 "
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionService": {
			"sparkJobSubmission.LivyNoBatchIdReturned": "応答から Spark ジョブ バッチ ID は返されません。{0}[エラー]{1}",
			"sparkJobSubmission.LivyNoLogReturned": "応答で返されたログはありません。{0}[エラー] {1}"
		},
		"dist/sqlClusterLookUp": {
			"bdcConnectError": "エラー: {0}。",
			"promptBDCPassword": "BDC コントローラーに接続するためのパスワードを指定してください",
			"promptBDCUsername": "{0}BDC コントローラーに接続するためのユーザー名を指定してください:",
			"usernameAndPasswordRequired": "ユーザー名とパスワードが必要です"
		},
		"dist/sqlToolsServer": {
			"downloadServiceDoneChannelMsg": "{0} のインストールが完了しました",
			"downloadingServiceChannelMsg": "{0} のダウンロード中",
			"downloadingServiceSizeChannelMsg": "({0} KB)",
			"downloadingServiceStatusMsg": "{0} のダウンロード中",
			"entryExtractedChannelMsg": "{0} を抽出しました ({1}/{2})",
			"failedToStartServiceErrorMsg": "{0} を開始できませんでした",
			"installedServiceChannelMsg": "{0} がインストールされました",
			"installingServiceChannelMsg": "{0} を {1} にインストールしています",
			"installingServiceStatusMsg": "{0} のインストール中",
			"serviceStartedStatusMsg": "{0} が開始されました",
			"startingServiceStatusMsg": "{0} の開始中"
		},
		"dist/telemetry": {
			"serviceCrashMessage": "{0} コンポーネントが予期せず終了しました。Azure Data Studio を再起動してください。",
			"viewKnownIssuesText": "既知の問題の表示"
		},
		"package": {
			"cloud.databaseProperties.azureEdition": "エディション",
			"cloud.databaseProperties.compatibilityLevel": "互換性レベル",
			"cloud.databaseProperties.owner": "所有者",
			"cloud.databaseProperties.serviceLevelObjective": "価格レベル",
			"cloud.serverProperties.serverEdition": "種類",
			"cloud.serverProperties.serverVersion": "バージョン",
			"databasesListProperties.lastBackup": "前回のバックアップ",
			"databasesListProperties.name": "名前",
			"databasesListProperties.size": "サイズ (MB)",
			"databasesListProperties.status": "状態",
			"json.format.enable.desc": "既定の JSON フォーマッタを有効/無効にします (再起動が必要です)",
			"json.schemas.desc": "スキーマを現在のプロジェクトの JSON ファイルに関連付けます",
			"json.schemas.fileMatch.desc": "JSON ファイルをスキーマに解決するときに突き合わせるファイル パターンの配列です。",
			"json.schemas.fileMatch.item.desc": "JSON ファイルをスキーマに解決するときに突き合わせる、'*' を含められるファイル パターンです。",
			"json.schemas.schema.desc": "指定された URL のスキーマ定義です。スキーマは、スキーマ URL へのアクセスを避けるためにのみ指定する必要があります。",
			"json.schemas.url.desc": "スキーマへの URL または現在のディレクトリ内のスキーマへの相対パス",
			"mssql.configuration.title": "MSSQL 構成",
			"mssql.connectionOptions.applicationIntent.description": "サーバーに接続するときにアプリケーションのワークロードの種類を宣言します",
			"mssql.connectionOptions.applicationIntent.displayName": "アプリケーションの意図",
			"mssql.connectionOptions.applicationName.description": "アプリケーションの名前",
			"mssql.connectionOptions.applicationName.displayName": "アプリケーション名",
			"mssql.connectionOptions.asynchronousProcessing.description": "True の場合は、.Net Framework Data Provider の非同期機能を使用できるようになります",
			"mssql.connectionOptions.asynchronousProcessing.displayName": "非同期処理",
			"mssql.connectionOptions.attachDbFilename.displayName": "添付 DB ファイル名",
			"mssql.connectionOptions.attachedDBFileName.description": "完全なパス名を含む、接続可能なデータベースのプライマリ ファイル名",
			"mssql.connectionOptions.attachedDBFileName.displayName": "添付された DB ファイルの名前",
			"mssql.connectionOptions.authType.categoryValues.azureMFA": "Azure Active Directory - MFA サポート付きユニバーサル",
			"mssql.connectionOptions.authType.categoryValues.integrated": "Windows 認証",
			"mssql.connectionOptions.authType.categoryValues.sqlLogin": "SQL ログイン",
			"mssql.connectionOptions.authType.description": "SQL Server での認証方法を指定します",
			"mssql.connectionOptions.authType.displayName": "認証の種類",
			"mssql.connectionOptions.columnEncryptionSetting.description": "接続の Always Encrypted を有効または無効にする",
			"mssql.connectionOptions.columnEncryptionSetting.displayName": "Always Encrypted",
			"mssql.connectionOptions.connectRetryCount.description": "接続を復元するための試行回数",
			"mssql.connectionOptions.connectRetryCount.displayName": "接続の再試行回数",
			"mssql.connectionOptions.connectRetryInterval.description": "接続を復元するための試行間の遅延",
			"mssql.connectionOptions.connectRetryInterval.displayName": "接続の再試行間隔",
			"mssql.connectionOptions.connectTimeout.description": "サーバーへの接続が確立されるまでに待機する時間 (秒)。この時間が経過すると接続要求を終了し、エラーを生成します",
			"mssql.connectionOptions.connectTimeout.displayName": "接続タイムアウト",
			"mssql.connectionOptions.connectionName.description": "接続のカスタム名",
			"mssql.connectionOptions.connectionName.displayName": "名前 (省略可能)",
			"mssql.connectionOptions.contextConnection.description": "True の場合は、接続元が SQL Server のコンテキストであることを示します。SQL Server のプロセスで実行する場合のみ使用できます",
			"mssql.connectionOptions.contextConnection.displayName": "コンテキスト接続",
			"mssql.connectionOptions.currentLanguage.description": "SQL Server 言語レコード名",
			"mssql.connectionOptions.currentLanguage.displayName": "現在の言語",
			"mssql.connectionOptions.databaseName.description": "データ ソース内の初期カタログまたはデータベースの名前",
			"mssql.connectionOptions.databaseName.displayName": "データベース",
			"mssql.connectionOptions.enclaveAttestationProtocol.categoryValues.AAS": "Azure Attestation",
			"mssql.connectionOptions.enclaveAttestationProtocol.categoryValues.HGS": "ホスト ガーディアン サービス",
			"mssql.connectionOptions.enclaveAttestationProtocol.description": "セキュリティで保護されたエンクレーブが設定された Always Encrypted で使用されるサーバー側エンクレーブを構成証明するためのプロトコルを指定します。",
			"mssql.connectionOptions.enclaveAttestationProtocol.displayName": "構成証明プロトコル",
			"mssql.connectionOptions.enclaveAttestationUrl.description": "セキュリティで保護されたエンクレーブが設定された Always Encrypted で使用されるサーバー側エンクレーブを構成証明するためのエンドポイントを指定します。",
			"mssql.connectionOptions.enclaveAttestationUrl.displayName": "エンクレーブ構成証明 URL",
			"mssql.connectionOptions.encrypt.description": "True の場合、SQL Server は、サーバーに証明書がインストールされている場合は、クライアントとサーバー間で送信されるすべてのデータに SSL 暗号化を使用します",
			"mssql.connectionOptions.encrypt.displayName": "暗号化",
			"mssql.connectionOptions.failoverPartner.description": "フェールオーバー パートナーとして機能する SQL Server インスタンスの名前またはネットワーク アドレス",
			"mssql.connectionOptions.failoverPartner.displayName": "フェールオーバー パートナー",
			"mssql.connectionOptions.groupName.advanced": "詳細設定",
			"mssql.connectionOptions.groupName.connectionResiliency": "接続の復元性",
			"mssql.connectionOptions.groupName.context": "コンテキスト",
			"mssql.connectionOptions.groupName.initialization": "初期化",
			"mssql.connectionOptions.groupName.pooling": "プーリング",
			"mssql.connectionOptions.groupName.replication": "レプリケーション",
			"mssql.connectionOptions.groupName.security": "セキュリティ",
			"mssql.connectionOptions.groupName.source": "ソース",
			"mssql.connectionOptions.loadBalanceTimeout.description": "この接続が破棄される前にプールに存在する最小時間 (秒)",
			"mssql.connectionOptions.loadBalanceTimeout.displayName": "負荷分散タイムアウト",
			"mssql.connectionOptions.maxPoolSize.description": "プールに保持される接続の最大数",
			"mssql.connectionOptions.maxPoolSize.displayName": "最大プール サイズ",
			"mssql.connectionOptions.minPoolSize.description": "プールに保持される接続の最小数",
			"mssql.connectionOptions.minPoolSize.displayName": "最小プール サイズ",
			"mssql.connectionOptions.multiSubnetFailover.displayName": "マルチ サブネット フェールオーバー",
			"mssql.connectionOptions.multipleActiveResultSets.description": "True の場合は、1 つの接続から複数の結果セットが返され、これらを読み取ることができます",
			"mssql.connectionOptions.multipleActiveResultSets.displayName": "複数のアクティブな結果セット",
			"mssql.connectionOptions.packetSize.description": "SQL Server インスタンスとの通信に使用されるネットワーク パケットのサイズ (バイト)",
			"mssql.connectionOptions.packetSize.displayName": "パケット サイズ",
			"mssql.connectionOptions.password.description": "データ ソースへの接続時に使用するパスワードを示します",
			"mssql.connectionOptions.password.displayName": "パスワード",
			"mssql.connectionOptions.persistSecurityInfo.description": "False の場合、パスワードなどのセキュリティによる保護が要求される情報は、接続しても返されません",
			"mssql.connectionOptions.persistSecurityInfo.displayName": "セキュリティ情報を保持する",
			"mssql.connectionOptions.pooling.description": "True の場合、接続オブジェクトが適切なプールから取得されるか、または、必要に応じて接続オブジェクトが作成され、適切なプールに追加されます",
			"mssql.connectionOptions.pooling.displayName": "プーリング",
			"mssql.connectionOptions.port.displayName": "ポート",
			"mssql.connectionOptions.replication.description": "レプリケーション時に SQL Server によって使用されます",
			"mssql.connectionOptions.replication.displayName": "レプリケーション",
			"mssql.connectionOptions.serverName.description": "SQL Server インスタンスの名前",
			"mssql.connectionOptions.serverName.displayName": "サーバー",
			"mssql.connectionOptions.trustServerCertificate.description": "True (および encrypt=true) の場合、SQL Server は、サーバー証明書を検証せずに、クライアントとサーバーの間で送信されるすべてのデータに対して SSL 暗号化を使用します",
			"mssql.connectionOptions.trustServerCertificate.displayName": "サーバー証明書を信頼する",
			"mssql.connectionOptions.typeSystemVersion.description": "プロバイダーがデータ リーダー経由で公開するサーバーの種類のシステムを示します。",
			"mssql.connectionOptions.typeSystemVersion.displayName": "タイプ システムのバージョン",
			"mssql.connectionOptions.userName.description": "データ ソースへの接続時に使用するユーザー ID を示します",
			"mssql.connectionOptions.userName.displayName": "ユーザー名",
			"mssql.connectionOptions.workstationId.description": "SQL Server に接続しているワークステーションの名前",
			"mssql.connectionOptions.workstationId.displayName": "ワークステーション ID",
			"mssql.disabled": "無効",
			"mssql.enabled": "有効",
			"mssql.exportNotebookToSql": "ノートブックを SQL としてエクスポート",
			"mssql.exportSqlAsNotebook": "SQL をノートブックとしてエクスポート",
			"mssql.format.alignColumnDefinitionsInColumns": "列定義を揃えるかどうか",
			"mssql.format.datatypeCasing": "データ型を大文字、小文字、または 'なし' (元のまま) のいずれにフォーマットするか",
			"mssql.format.keywordCasing": "キーワードを大文字、小文字、または 'なし' (元のまま) のいずれにフォーマットするか",
			"mssql.format.placeCommasBeforeNextStatement": "コンマを、'mycolumn1,' のようにリスト内の各ステートメントの末尾に配置する代わりに ',mycolumn2' のように先頭に配置するかどうか",
			"mssql.format.placeSelectStatementReferencesOnNewLine": "たとえば 'SELECT C1, C2 FROM T1' の場合に C1 と C2 を別々の行にするように、Select ステートメント内のオブジェクトへの参照を別々の行に分割するかどうか",
			"mssql.ignorePlatformWarning": "[省略可能] サポートされていないプラットフォームの警告を表示しない",
			"mssql.intelliSense.enableErrorChecking": "IntelliSense エラー チェックを有効にするかどうか",
			"mssql.intelliSense.enableIntelliSense": "IntelliSense を有効にするかどうか",
			"mssql.intelliSense.enableQuickInfo": "IntelliSense クイック ヒントを有効にするかどうか",
			"mssql.intelliSense.enableSuggestions": "IntelliSense 提案を有効にするかどうか",
			"mssql.intelliSense.lowerCaseSuggestions": "IntelliSense 提案を小文字にするかどうか",
			"mssql.logDebugInfo": "[省略可能] コンソールへのデバッグ出力をログに記録し ([表示] -> [出力])、ドロップダウンから適切な出力チャネルを選択します",
			"mssql.logFilesRemovalLimit": "mssql.logRetentionMinutes の有効期限が切れた、起動時に削除する古いファイルの最大数。この制限のためにクリーンアップされないファイルは、Azure Data Studio の次回の起動時にクリーンアップされます。",
			"mssql.logRetentionMinutes": "バックエンド サービスのログ ファイルを保持する分単位の時間。既定値は 1 週間です。",
			"mssql.provider.displayName": "Microsoft SQL Server",
			"mssql.query.alwaysEncryptedParameterization": "Always Encrypted のパラメーター化を有効にする",
			"mssql.query.ansiDefaults": "SET ANSI_DEFAULTS を有効にする",
			"mssql.query.ansiNullDefaultOn": "SET ANSI_NULL_DFLT_ON を有効にする",
			"mssql.query.ansiNulls": "SET ANSI_NULLS を有効にする",
			"mssql.query.ansiPadding": "SET ANSI_PADDING を有効にする",
			"mssql.query.ansiWarnings": "SET ANSI_WARNINGS を有効にする",
			"mssql.query.arithAbort": "SET ARITHABORT オプションを有効にする",
			"mssql.query.cursorCloseOnCommit": "SET CURSOR_CLOSE_ON_COMMIT を有効にする",
			"mssql.query.deadlockPriority": "SET DEADLOCK_PRIORITY オプションを有効にする",
			"mssql.query.displayBitAsNumber": "ビット列を数値 (1 または 0) として表示するかどうか。False の場合、ビット列は 'true' または 'false' として表示されます",
			"mssql.query.executionTimeout": "実行タイムアウトが 0 の場合は、無制限の待機 (タイムアウトなし) を示します",
			"mssql.query.implicitTransactions": "SET IMPLICIT_TRANSACTIONS を有効にする",
			"mssql.query.lockTimeout": "SET LOCK TIMEOUT オプションを有効にする (ミリ秒単位)",
			"mssql.query.maxXmlCharsToStore": "クエリの実行後に格納する XML 文字の数",
			"mssql.query.noCount": "SET NOCOUNT オプションを有効にする",
			"mssql.query.noExec": "SET NOEXEC オプションを有効にする",
			"mssql.query.parseOnly": "SET PARSEONLY オプションを有効にする",
			"mssql.query.queryGovernorCostLimit": "SET QUERY_GOVERNOR_COST_LIMIT を有効にする",
			"mssql.query.quotedIdentifier": "SET QUOTED_IDENTIFIER を有効にする",
			"mssql.query.setRowCount": "サーバーがクエリの処理を停止する前に返す行の最大数。",
			"mssql.query.statisticsIO": "SET STATISTICS IO オプションを有効にする",
			"mssql.query.statisticsTime": "SET STATISTICS TIME オプションを有効にする",
			"mssql.query.textSize": "SELECT ステートメントから返されるテキストおよび ntext データの最大サイズ",
			"mssql.query.transactionIsolationLevel": "SET TRANSACTION ISOLATION LEVEL オプションを有効にする",
			"mssql.query.xactAbortOn": "SET XACT_ABORT ON オプションを有効にする",
			"mssql.tracingLevel": "[省略可能] バックエンド サービスのログ レベル。Azure Data Studio は開始のたびにファイル名を生成し、そのファイルが既に存在する場合にはログ エントリが対象ファイルに追加されます。古いログ ファイルのクリーンアップについては、logRetentionMinutes と logFilesRemovalLimit の設定を参照してください。既定の tracingLevel では、ログに記録される数は多くありません。詳細レベルを変更すると、詳細なログが記録され、ログのためのディスク容量が必要になる場合があります。エラーには重大が含まれ、警告にはエラーが含まれ、情報には警告が含まれ、詳細には情報が含まれます",
			"mssqlCluster.copyPath": "パスのコピー",
			"mssqlCluster.deleteFiles": "削除",
			"mssqlCluster.manageAccess": "アクセスの管理",
			"mssqlCluster.mkdir": "新しいディレクトリ",
			"mssqlCluster.previewFile": "プレビュー",
			"mssqlCluster.saveFile": "保存",
			"mssqlCluster.uploadFiles": "ファイルのアップロード",
			"notebook.command.new": "新しいノートブック",
			"notebook.command.open": "ノートブックを開く",
			"objectsListProperties.name": "名前",
			"onprem.databaseProperties.compatibilityLevel": "互換性レベル",
			"onprem.databaseProperties.lastBackupDate": "前回のデータベース バックアップ",
			"onprem.databaseProperties.lastLogBackupDate": "最終ログ バックアップ",
			"onprem.databaseProperties.owner": "所有者",
			"onprem.databaseProperties.recoveryModel": "復旧モデル",
			"onprem.serverProperties.machineName": "コンピューター名",
			"onprem.serverProperties.osVersion": "OS バージョン",
			"onprem.serverProperties.serverEdition": "エディション",
			"onprem.serverProperties.serverVersion": "バージョン",
			"tab.bigDataClusterDescription": "SQL Server ビッグ データ クラスターに関するタスクと情報",
			"title.bigDataCluster": "SQL Server ビッグ データ クラスター",
			"title.books": "ノートブック",
			"title.clearSearchServerResult": "検索: 検索サーバーの結果を消去する",
			"title.configurePython": "ノートブック用 Python の構成",
			"title.designTable": "デザイン",
			"title.endpoints": "サービス エンドポイント",
			"title.installPackages": "パッケージのインストール",
			"title.newSparkJob": "新しい Spark ジョブ",
			"title.newTable": "新しいテーブル",
			"title.openClusterDashboard": "クラスター\r\nダッシュボード",
			"title.openSparkHistory": "Spark 履歴の表示",
			"title.openYarnHistory": "Yarn 履歴の表示",
			"title.searchServers": "検索: サーバー",
			"title.showLogFile": "ログ ファイルの表示",
			"title.submitSparkJob": "Spark ジョブの送信",
			"title.tasks": "タスク"
		}
	}
}