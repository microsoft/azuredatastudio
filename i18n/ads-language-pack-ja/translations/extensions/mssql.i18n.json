{
	"": [
		"--------------------------------------------------------------------------------------------",
		"Copyright (c) Microsoft Corporation. All rights reserved.",
		"Licensed under the Source EULA. See License.txt in the project root for license information.",
		"--------------------------------------------------------------------------------------------",
		"Do not edit this file. It is machine generated."
	],
	"version": "1.0.0",
	"contents": {
		"package": {
			"json.schemas.desc": "スキーマを現在のプロジェクトの JSON ファイルに関連付けます",
			"json.schemas.url.desc": "スキーマへの URL または現在のディレクトリ内のスキーマへの相対パス",
			"json.schemas.fileMatch.desc": "JSON ファイルをスキーマに解決するときに突き合わせるファイル パターンの配列です。",
			"json.schemas.fileMatch.item.desc": "JSON ファイルをスキーマに解決するときに突き合わせる、'*' を含められるファイル パターンです。",
			"json.schemas.schema.desc": "指定された URL のスキーマ定義です。スキーマは、スキーマ URL へのアクセスを避けるためにのみ指定する必要があります。",
			"json.format.enable.desc": "既定の JSON フォーマッタを有効/無効にします (再起動が必要です)",
			"mssqlCluster.uploadFiles": "ファイルのアップロード",
			"mssqlCluster.mkdir": "新しいディレクトリ",
			"mssqlCluster.deleteFiles": "削除",
			"mssqlCluster.previewFile": "プレビュー",
			"mssqlCluster.saveFile": "保存",
			"mssqlCluster.copyPath": "パスのコピー",
			"mssqlCluster.manageAccess": "アクセスの管理",
			"notebook.command.new": "新しいノートブック",
			"notebook.command.open": "ノートブックを開く",
			"tab.bigDataClusterDescription": "SQL Server ビッグ データ クラスターに関するタスクと情報",
			"title.bigDataCluster": "SQL Server ビッグ データ クラスター",
			"title.submitSparkJob": "Spark ジョブの送信",
			"title.newSparkJob": "新しい Spark ジョブ",
			"title.openSparkHistory": "Spark 履歴の表示",
			"title.openYarnHistory": "Yarn 履歴の表示",
			"title.tasks": "タスク",
			"title.installPackages": "パッケージのインストール",
			"title.configurePython": "ノートブック用 Python の構成",
			"title.searchServers": "検索: サーバー",
			"title.clearSearchServerResult": "検索: 検索サーバーの結果を消去する",
			"title.endpoints": "サービス エンドポイント",
			"title.books": "ノートブック",
			"title.showLogFile": "ログ ファイルの表示",
			"mssql.configuration.title": "MSSQL 構成",
			"mssql.query.displayBitAsNumber": "ビット列を数値 (1 または 0) として表示するかどうか。False の場合、ビット列は 'true' または 'false' として表示されます",
			"mssql.format.alignColumnDefinitionsInColumns": "列定義を揃えるかどうか",
			"mssql.format.datatypeCasing": "データ型を大文字、小文字、または 'なし' (元のまま) のいずれにフォーマットするか",
			"mssql.format.keywordCasing": "キーワードを大文字、小文字、または 'なし' (元のまま) のいずれにフォーマットするか",
			"mssql.format.placeCommasBeforeNextStatement": "コンマを、'mycolumn1,' のようにリスト内の各ステートメントの末尾に配置する代わりに ',mycolumn2' のように先頭に配置するかどうか",
			"mssql.format.placeSelectStatementReferencesOnNewLine": "たとえば 'SELECT C1, C2 FROM T1' の場合に C1 と C2 を別々の行にするように、Select ステートメント内のオブジェクトへの参照を別々の行に分割するかどうか",
			"mssql.logDebugInfo": "[省略可能] コンソールへのデバッグ出力をログに記録し ([表示] -> [出力])、ドロップダウンから適切な出力チャネルを選択します",
			"mssql.tracingLevel": "[省略可能] バックエンド サービスのログ レベル。Azure Data Studio は開始のたびにファイル名を生成し、そのファイルが既に存在する場合にはログ エントリが対象ファイルに追加されます。古いログ ファイルのクリーンアップについては、logRetentionMinutes と logFilesRemovalLimit の設定を参照してください。既定の tracingLevel では、ログに記録される数は多くありません。詳細レベルを変更すると、詳細なログが記録され、ログのためのディスク容量が必要になる場合があります。エラーには重大が含まれ、警告にはエラーが含まれ、情報には警告が含まれ、詳細には情報が含まれます",
			"mssql.logRetentionMinutes": "バックエンド サービスのログ ファイルを保持する分単位の時間。既定値は 1 週間です。",
			"mssql.logFilesRemovalLimit": "mssql.logRetentionMinutes の有効期限が切れた、起動時に削除する古いファイルの最大数。この制限のためにクリーンアップされないファイルは、Azure Data Studio の次回の起動時にクリーンアップされます。",
			"ignorePlatformWarning": "[省略可能] サポートされていないプラットフォームの警告を表示しない",
			"onprem.databaseProperties.recoveryModel": "復旧モデル",
			"onprem.databaseProperties.lastBackupDate": "前回のデータベース バックアップ",
			"onprem.databaseProperties.lastLogBackupDate": "最終ログ バックアップ",
			"onprem.databaseProperties.compatibilityLevel": "互換性レベル",
			"onprem.databaseProperties.owner": "所有者",
			"onprem.serverProperties.serverVersion": "バージョン",
			"onprem.serverProperties.serverEdition": "エディション",
			"onprem.serverProperties.machineName": "コンピューター名",
			"onprem.serverProperties.osVersion": "OS バージョン",
			"cloud.databaseProperties.azureEdition": "エディション",
			"cloud.databaseProperties.serviceLevelObjective": "価格レベル",
			"cloud.databaseProperties.compatibilityLevel": "互換性レベル",
			"cloud.databaseProperties.owner": "所有者",
			"cloud.serverProperties.serverVersion": "バージョン",
			"cloud.serverProperties.serverEdition": "種類",
			"mssql.provider.displayName": "Microsoft SQL Server",
			"mssql.connectionOptions.connectionName.displayName": "名前 (省略可能)",
			"mssql.connectionOptions.connectionName.description": "接続のカスタム名",
			"mssql.connectionOptions.serverName.displayName": "サーバー",
			"mssql.connectionOptions.serverName.description": "SQL Server インスタンスの名前",
			"mssql.connectionOptions.databaseName.displayName": "データベース",
			"mssql.connectionOptions.databaseName.description": "データ ソース内の初期カタログまたはデータベースの名前",
			"mssql.connectionOptions.authType.displayName": "認証の種類",
			"mssql.connectionOptions.authType.description": "SQL Server での認証方法を指定します",
			"mssql.connectionOptions.authType.categoryValues.sqlLogin": "SQL ログイン",
			"mssql.connectionOptions.authType.categoryValues.integrated": "Windows 認証",
			"mssql.connectionOptions.authType.categoryValues.azureMFA": "Azure Active Directory - MFA サポート付きユニバーサル",
			"mssql.connectionOptions.userName.displayName": "ユーザー名",
			"mssql.connectionOptions.userName.description": "データ ソースへの接続時に使用するユーザー ID を示します",
			"mssql.connectionOptions.password.displayName": "パスワード",
			"mssql.connectionOptions.password.description": "データ ソースへの接続時に使用するパスワードを示します",
			"mssql.connectionOptions.applicationIntent.displayName": "アプリケーションの意図",
			"mssql.connectionOptions.applicationIntent.description": "サーバーに接続するときにアプリケーションのワークロードの種類を宣言します",
			"mssql.connectionOptions.asynchronousProcessing.displayName": "非同期処理",
			"mssql.connectionOptions.asynchronousProcessing.description": "True の場合は、.Net Framework Data Provider の非同期機能を使用できるようになります",
			"mssql.connectionOptions.connectTimeout.displayName": "接続タイムアウト",
			"mssql.connectionOptions.connectTimeout.description": "サーバーへの接続が確立されるまでに待機する時間 (秒)。この時間が経過すると接続要求を終了し、エラーを生成します",
			"mssql.connectionOptions.currentLanguage.displayName": "現在の言語",
			"mssql.connectionOptions.currentLanguage.description": "SQL Server 言語レコード名",
			"mssql.connectionOptions.columnEncryptionSetting.displayName": "列暗号化",
			"mssql.connectionOptions.columnEncryptionSetting.description": "接続上のすべてのコマンドの既定の列暗号化設定",
			"mssql.connectionOptions.encrypt.displayName": "暗号化",
			"mssql.connectionOptions.encrypt.description": "True の場合、SQL Server は、サーバーに証明書がインストールされている場合は、クライアントとサーバー間で送信されるすべてのデータに SSL 暗号化を使用します",
			"mssql.connectionOptions.persistSecurityInfo.displayName": "セキュリティ情報を保持する",
			"mssql.connectionOptions.persistSecurityInfo.description": "False の場合、パスワードなどのセキュリティによる保護が要求される情報は、接続しても返されません",
			"mssql.connectionOptions.trustServerCertificate.displayName": "サーバー証明書を信頼する",
			"mssql.connectionOptions.trustServerCertificate.description": "True (および encrypt=true) の場合、SQL Server は、サーバー証明書を検証せずに、クライアントとサーバーの間で送信されるすべてのデータに対して SSL 暗号化を使用します",
			"mssql.connectionOptions.attachedDBFileName.displayName": "添付された DB ファイルの名前",
			"mssql.connectionOptions.attachedDBFileName.description": "完全なパス名を含む、接続可能なデータベースのプライマリ ファイル名",
			"mssql.connectionOptions.contextConnection.displayName": "コンテキスト接続",
			"mssql.connectionOptions.contextConnection.description": "True の場合は、接続元が SQL Server のコンテキストであることを示します。SQL Server のプロセスで実行する場合のみ使用できます",
			"mssql.connectionOptions.port.displayName": "ポート",
			"mssql.connectionOptions.connectRetryCount.displayName": "接続の再試行回数",
			"mssql.connectionOptions.connectRetryCount.description": "接続を復元するための試行回数",
			"mssql.connectionOptions.connectRetryInterval.displayName": "接続の再試行間隔",
			"mssql.connectionOptions.connectRetryInterval.description": "接続を復元するための試行間の遅延",
			"mssql.connectionOptions.applicationName.displayName": "アプリケーション名",
			"mssql.connectionOptions.applicationName.description": "アプリケーションの名前",
			"mssql.connectionOptions.workstationId.displayName": "ワークステーション ID",
			"mssql.connectionOptions.workstationId.description": "SQL Server に接続しているワークステーションの名前",
			"mssql.connectionOptions.pooling.displayName": "プーリング",
			"mssql.connectionOptions.pooling.description": "True の場合、接続オブジェクトが適切なプールから取得されるか、または、必要に応じて接続オブジェクトが作成され、適切なプールに追加されます",
			"mssql.connectionOptions.maxPoolSize.displayName": "最大プール サイズ",
			"mssql.connectionOptions.maxPoolSize.description": "プールに保持される接続の最大数",
			"mssql.connectionOptions.minPoolSize.displayName": "最小プール サイズ",
			"mssql.connectionOptions.minPoolSize.description": "プールに保持される接続の最小数",
			"mssql.connectionOptions.loadBalanceTimeout.displayName": "負荷分散タイムアウト",
			"mssql.connectionOptions.loadBalanceTimeout.description": "この接続が破棄される前にプールに存在する最小時間 (秒)",
			"mssql.connectionOptions.replication.displayName": "レプリケーション",
			"mssql.connectionOptions.replication.description": "レプリケーション時に SQL Server によって使用されます",
			"mssql.connectionOptions.attachDbFilename.displayName": "添付 DB ファイル名",
			"mssql.connectionOptions.failoverPartner.displayName": "フェールオーバー パートナー",
			"mssql.connectionOptions.failoverPartner.description": "フェールオーバー パートナーとして機能する SQL Server インスタンスの名前またはネットワーク アドレス",
			"mssql.connectionOptions.multiSubnetFailover.displayName": "マルチ サブネット フェールオーバー",
			"mssql.connectionOptions.multipleActiveResultSets.displayName": "複数のアクティブな結果セット",
			"mssql.connectionOptions.multipleActiveResultSets.description": "True の場合は、1 つの接続から複数の結果セットが返され、これらを読み取ることができます",
			"mssql.connectionOptions.packetSize.displayName": "パケット サイズ",
			"mssql.connectionOptions.packetSize.description": "SQL Server インスタンスとの通信に使用されるネットワーク パケットのサイズ (バイト)",
			"mssql.connectionOptions.typeSystemVersion.displayName": "タイプ システムのバージョン",
			"mssql.connectionOptions.typeSystemVersion.description": "DataReader を通してプロバイダーが公開するサーバー タイプのシステムを示します"
		},
		"dist/localizedConstants": {
			"msgMissingNodeContext": "ノードが渡されずに呼び出されたノード コマンド",
			"mssql.manageAccessTitle": "アクセスの管理",
			"mssql.locationTitle": "場所: ",
			"mssql.permissionsTitle": "アクセス許可",
			"mssql.ownerPostfix": " - 所有者",
			"mssql.owningGroupPostfix": " - 所有グループ",
			"mssql.everyone": "他のすべてのユーザー",
			"mssql.userLabel": "ユーザー",
			"mssql.groupLabel": "グループ",
			"mssql.accessHeader": "アクセス",
			"mssql.defaultHeader": "既定",
			"mssql.delete": "削除",
			"mssql.stickyHeader": "付箋",
			"mssql.inheritDefaultsLabel": "既定値の継承",
			"mssql.readHeader": "読み取り",
			"mssql.writeHeader": "書き込み",
			"mssql.executeHeader": "実行",
			"mssql.addUserOrGroup": "ユーザーまたはグループの追加",
			"mssql.enterNamePlaceholder": "名前の入力",
			"mssql.addLabel": "追加",
			"mssql.namedUsersAndGroups": "名前付きユーザーとグループ",
			"mssql.apply": "適用",
			"mssql.applyRecursively": "再帰的に適用",
			"mssql.errorApplyingAclChanges": "変更の適用中に予期しないエラーが発生しました: {0}",
			"sparkJobSubmission_LocalFileDestinationHint": "ローカル ファイルは HDFS にアップロードされます。 ",
			"sparkJobSubmission_SubmissionEndMessage": ".......................... Spark ジョブの送信終了 ............................",
			"sparkJobSubmission_PrepareUploadingFile": "ローカル {0} から HDFS フォルダーへファイルをアップロードしています: {1}",
			"sparkJobSubmission_UploadingFileSucceeded": "ファイルがクラスターに正常にアップロードされました。",
			"sparkJobSubmission_UploadingFileFailed": "ファイルをクラスターにアップロードできませんでした。{0}",
			"sparkJobSubmission_PrepareSubmitJob": "ジョブ {0} を送信しています...",
			"sparkJobSubmission_SubmitJobFinished": "Spark ジョブが送信されました。",
			"sparkJobSubmission_SubmitJobFailed": "Spark ジョブを送信できませんでした。{0} ",
			"sparkJobSubmission_YarnUIMessage": "YarnUI URL: {0} ",
			"sparkJobSubmission_SparkHistoryLinkMessage": "Spark 履歴 URL: {0} ",
			"sparkJobSubmission_GetApplicationIdFailed": "アプリケーション ID の取得に失敗しました。{0}",
			"sparkJobSubmission_LocalFileNotExisted": "ローカル ファイル {0} が存在しません。 ",
			"sparkJobSubmission_NoSqlBigDataClusterFound": "SQL Server ビッグ データ クラスターが見つかりません。"
		},
		"dist/objectExplorerNodeProvider/fileSources": {
			"maxSizeNotice": "注意: このファイルはプレビュー用に {0} で切り詰められました。 ",
			"maxSizeReached": "ファイルはプレビュー用に {0} で切り捨てられました。"
		},
		"dist/objectExplorerNodeProvider/command": {
			"progress": "$(sync~spin) {0}...",
			"cancelTooltip": "キャンセル",
			"cancel": "操作をキャンセルしますか?",
			"mssql.searchServers": "サーバー名を検索"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionService": {
			"sparkJobSubmission_LivyNoBatchIdReturned": "応答から Spark ジョブ バッチ ID は返されません。{0}[エラー]{1}",
			"sparkJobSubmission_LivyNoLogReturned": "応答で返されたログはありません。{0}[エラー] {1}"
		},
		"dist/objectExplorerNodeProvider/hdfsCommands": {
			"allFiles": "すべてのファイル",
			"lblUploadFiles": "アップロード",
			"uploading": "HDFS にファイルをアップロードしています",
			"uploadCanceled": "アップロード操作が取り消されました",
			"uploadError": "ファイルのアップロードでエラーが発生しました: {0}",
			"makingDir": "ディレクトリを作成しています",
			"mkdirCanceled": "操作が取り消されました",
			"mkDirError": "ディレクトリの作成でエラーが発生しました: {0}",
			"enterDirName": "ディレクトリ名を入力する",
			"deleteError": "ファイルの削除でエラーが発生しました: {0}",
			"msgDeleteFolder": "対象フォルダーとその内容を削除してもよろしいですか?",
			"msgDeleteFile": "このファイルを削除しますか?",
			"saving": "HDFS ファイルを保存しています",
			"saveCanceled": "保存操作は取り消されました",
			"saveError": "ファイルの保存でエラーが発生しました: {0}",
			"previewing": "プレビューを生成しています",
			"previewError": "ファイルのプレビューでエラーが発生しました: {0}",
			"copyPathError": "パスのコピーでエラーが発生しました: {0}",
			"manageAccessError": "[アクセスの管理] ダイアログを開いている間に予期しないエラーが発生しました: {0}"
		},
		"dist/hdfs/webhdfs": {
			"webhdfs.invalidDataStructure": "無効なデータ構造",
			"webhdfs.missingProperties": "オプションが不足しているため、WebHDFS クライアントを作成できません: ${0}",
			"webhdfs.undefinedArgument": "'${0}' は未定義です。",
			"webhdfs.httpError400": "無効な要求",
			"webhdfs.httpError401": "許可されていません",
			"webhdfs.httpError403": "禁止されています",
			"webhdfs.httpError404": "見つかりません",
			"webhdfs.httpError500": "内部サーバー エラー",
			"webhdfs.unknownError": "不明なエラー",
			"webhdfs.unexpectedRedirect": "予期しないリダイレクト"
		},
		"dist/objectExplorerNodeProvider/connection": {
			"connectionInfoUndefined": "ConnectionInfo が定義されていません。",
			"connectionInfoOptionsUndefined": "ConnectionInfo.options が定義されていません。",
			"connectionInfoOptionsMissingProperties": "connectionInfo.options で一部のプロパティが不足しています: {0}"
		},
		"dist/telemetry": {
			"viewKnownIssuesText": "既知の問題の表示",
			"serviceCrashMessage": "{0} コンポーネントが予期せず終了しました。Azure Data Studio を再起動してください。"
		},
		"dist/main": {
			"msgSampleCodeDataFrame": "このサンプル コードは、ファイルをデータ フレームに読み込み、最初の 10 件の結果を示します。",
			"notebookFileType": "ノートブック",
			"unsupportedFileType": ".ipynb ノートブックのみがサポートされています",
			"fileNotFound": "指定されたファイルが見つかりません"
		},
		"dist/hdfs/hdfsModel": {
			"mssql.recursivePermissionOpStarted": "アクセス許可の変更を '{0}' に再帰的に適用しています",
			"mssql.recursivePermissionOpSucceeded": "アクセス許可の変更が正常に適用されました。",
			"mssql.recursivePermissionOpProgress": "アクセス許可の変更を '{0}' に適用しています。",
			"mssql.recursivePermissionOpError": "アクセス許可の変更の適用でエラーが発生しました: {0}"
		},
		"dist/prompts/confirm": {
			"msgYes": "はい",
			"msgNo": "いいえ"
		},
		"dist/sparkFeature/dialog/dialogCommands": {
			"selectOtherServer": "他の SQL Server を選択する",
			"sparkJobSubmission_PleaseSelectSqlWithCluster": "ビッグ データ クラスターが含まれる SQL Server を選択してください。",
			"sparkJobSubmission_NoSqlSelected": "SQL Server が選択されていません。",
			"errorNotSqlBigDataCluster": "選択したサーバーが SQL Server ビッグ データ クラスターに属していません",
			"sparkJobSubmission_GetFilePathFromSelectedNodeFailed": "ファイル パス取得エラー: {0}"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionDialog": {
			"sparkJobSubmission_SparkJobSubmissionDialogInitializeError": "SparkJobSubmissionDialog のパラメーターが無効です",
			"sparkJobSubmission_DialogTitleNewJob": "新しいジョブ",
			"sparkJobSubmission_DialogCancelButton": "キャンセル",
			"sparkJobSubmission_DialogSubmitButton": "送信",
			"sparkJobSubmission_SubmitSparkJob": "{0} Spark ジョブの送信:",
			"sparkJobSubmission_SubmissionStartMessage": ".......................... Spark ジョブの送信開始 .........................."
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionModel": {
			"sparkJobSubmission_SparkJobSubmissionModelInitializeError": "SparkJobSubmissionModel のパラメーターが無効です",
			"sparkJobSubmission_submissionArgsIsInvalid": "submissionArgs が無効です。 ",
			"sparkJobSubmission_LivyBatchIdIsInvalid": "livyBatchId が無効です。 ",
			"sparkJobSubmission_GetApplicationIdTimeOut": "アプリケーション ID の取得タイムアウト。{0}[ログ]   {1}",
			"sparkJobSubmission_localFileOrFolderNotSpecified.": "プロパティ localFilePath または hdfsFolderPath が指定されていません。 ",
			"sparkJobSubmission_PathNotSpecified.": "プロパティ パスが指定されていません。 "
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkConfigurationTab": {
			"sparkJobSubmission_GeneralTabName": "全般",
			"sparkJobSubmission_JobNamePlaceHolder": "名前の入力...",
			"sparkJobSubmission_JobName": "ジョブ名",
			"sparkJobSubmission_SparkCluster": "Spark クラスター",
			"sparkJobSubmission_FilePathPlaceHolder": ".jar ファイルまたは .py ファイルへのパス",
			"sparkJobSubmission_LocalFileDestinationHintWithPath": "選択したローカル ファイルが HDFS にアップロードされます: {0}",
			"sparkJobSubmission_MainFilePath": "JAR/py ファイル",
			"sparkJobSubmission_MainClass": "メイン クラス",
			"sparkJobSubmission_Arguments": "引数",
			"sparkJobSubmission_ArgumentsTooltip": "メイン クラスで使用されるコマンド ライン引数。複数の引数を使うには、スペースで区切る必要があります。",
			"sparkJobSubmission_NotSpecifyJobName": "プロパティ ジョブ名が指定されていません。",
			"sparkJobSubmission_NotSpecifyJARPYPath": "プロパティ JAR/py ファイルが指定されていません。",
			"sparkJobSubmission_NotSpecifyMainClass": "プロパティ メイン クラスが指定されていません。",
			"sparkJobSubmission_HDFSFileNotExistedWithPath": "{0} がクラスターに存在しないか、例外がスローされました。 ",
			"sparkJobSubmission_HDFSFileNotExisted": "指定された HDFS ファイルが存在しません。 ",
			"sparkSelectLocalFile": "選択",
			"sparkJobSubmission_SelectFileError": "次のエラーが原因で、ファイルの検索でエラーが発生しました: {0}"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkAdvancedTab": {
			"sparkJobSubmission_AdvancedTabName": "詳細",
			"sparkJobSubmission_ReferenceJarList": "Jar を参照する",
			"sparkJobSubmission_ReferenceJarListToolTip": "Executor 作業ディレクトリに配置される Jar。Jar パスは HDFS パスにする必要があります。複数のパスはセミコロン (;) で区切ってください",
			"sparkJobSubmission_ReferencePyList": "参照 py ファイル",
			"sparkJobSubmission_ReferencePyListTooltip": "Executor 作業ディレクトリに配置される Py ファイル。ファイル パスは HDFS パスにする必要があります。複数のパスはセミコロン (;) で区切ってください",
			"sparkJobSubmission_ReferenceFilesList": "参照ファイル",
			"sparkJobSubmission_ReferenceFilesListTooltip": "Executor 作業ディレクトリに配置されるファイル。ファイル パスは HDFS パスにする必要があります。複数のパスはセミコロン (;) で区切ってください"
		},
		"dist/objectExplorerNodeProvider/objectExplorerNodeProvider": {
			"prmptPwd": "HDFS に接続するためのパスワードを入力してください:",
			"sessionNotFound": "ノード {0} のセッションが存在しません",
			"notifyError": "ノード変更の通知でエラーが発生しました: {0}",
			"hdfsFolder": "HDFS",
			"rootLabel": "ルート"
		},
		"dist/objectExplorerNodeProvider/hdfsProvider": {
			"errorExpanding": "エラー: {0}",
			"errDeleteConnectionNode": "接続を削除できません。削除できるのはサブフォルダーとファイルのみです。"
		},
		"dist/objectExplorerNodeProvider/cancelableStream": {
			"streamCanceled": "ユーザーによって取り消されたストリーム操作"
		},
		"dist/dashboard/serviceEndpoints": {
			"grafana": "メトリック ダッシュボード",
			"kibana": "ログ検索ダッシュボード",
			"sparkHistory": "Spark ジョブの管理と監視ダッシュボード",
			"yarnHistory": "Spark 診断と監視ダッシュボード",
			"copyText": "コピー",
			"endpoint.appproxy": "アプリケーション プロキシ",
			"endpoint.controller": "クラスター管理サービス",
			"endpoint.gateway": "HDFS ファイルにアクセスするためのゲートウェイ、Spark",
			"endpoint.managementproxy": "管理プロキシ",
			"endpoint.mgmtproxy": "管理プロキシ",
			"endpoint.sqlServerEndpoint": "SQL Server マスター インスタンス フロントエンド",
			"endpoint.grafana": "メトリック ダッシュボード",
			"endpoint.kibana": "ログ検索ダッシュボード",
			"endpoint.yarnHistory": "Spark 診断と監視ダッシュボード",
			"endpoint.sparkHistory": "Spark ジョブの管理と監視ダッシュボード",
			"endpoint.webhdfs": "HDFS ファイル システム プロキシ",
			"endpoint.livy": "Spark ステートメント、ジョブ、アプリケーションを実行するためのプロキシ"
		},
		"dist/sqlToolsServer": {
			"serviceStartedStatusMsg": "{0} が開始されました",
			"startingServiceStatusMsg": "{0} の開始中",
			"failedToStartServiceErrorMsg": "{0} を開始できませんでした",
			"installingServiceChannelMsg": "{0} を {1} にインストールしています",
			"installingServiceStatusMsg": "{0} のインストール中",
			"installedServiceChannelMsg": "{0} がインストールされました",
			"downloadingServiceChannelMsg": "{0} のダウンロード中",
			"downloadingServiceSizeChannelMsg": "({0} KB)",
			"downloadingServiceStatusMsg": "{0} のダウンロード中",
			"downloadServiceDoneChannelMsg": "{0} のインストールが完了しました"
		}
	}
}