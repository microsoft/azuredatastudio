{
	"": [
		"--------------------------------------------------------------------------------------------",
		"Copyright (c) Microsoft Corporation. All rights reserved.",
		"Licensed under the Source EULA. See License.txt in the project root for license information.",
		"--------------------------------------------------------------------------------------------",
		"Do not edit this file. It is machine generated."
	],
	"version": "1.0.0",
	"contents": {
		"dist/dashboard/serviceEndpoints": {
			"copyText": "Copiar",
			"endpoint.appproxy": "Proxy de aplicación",
			"endpoint.controller": "Servicio de administración de clústeres",
			"endpoint.gateway": "Puerta de enlace para acceder a archivos HDFS, Spark",
			"endpoint.grafana": "Panel de métricas",
			"endpoint.kibana": "Panel de búsqueda de registros",
			"endpoint.livy": "Proxy para ejecutar instrucciones, trabajos, aplicaciones de Spark",
			"endpoint.managementproxy": "Proxy de administración",
			"endpoint.mgmtproxy": "Proxy de administración",
			"endpoint.sparkHistory": "Panel de supervisión y administración de trabajos de Spark",
			"endpoint.sqlServerEndpoint": "Front-end de instancia maestra de SQL Server",
			"endpoint.webhdfs": "Proxy de sistema de archivos HDFS",
			"endpoint.yarnHistory": "Panel de diagnóstico y supervisión de Spark",
			"grafana": "Panel de métricas",
			"kibana": "Panel de búsqueda de registros",
			"sparkHistory": "Panel de supervisión y administración de trabajos de Spark",
			"yarnHistory": "Panel de diagnóstico y supervisión de Spark"
		},
		"dist/features": {
			"mssql.canceledLinkedAzureAccountSelection": "Azure Data Studio debe ponerse en contacto con Azure Key Vault para acceder a la clave maestra de una columna para Always Encrypted, pero no se ha seleccionado ninguna cuenta de Azure vinculada. Vuelva a intentar realizar la consulta y, cuando se le solicite, seleccione una cuenta de Azure vinculada.",
			"mssql.chooseLinkedAzureAccount": "Seleccione una cuenta de Azure vinculada:",
			"mssql.insufficientlyPrivelagedAzureAccount": "La cuenta de Azure configurada para {0} no tiene suficientes permisos para que Azure Key Vault tenga acceso a una clave maestra de columna para Always Encrypted.",
			"mssql.missingLinkedAzureAccount": "Azure Data Studio debe ponerse en contacto con Azure Key Vault para acceder a la clave maestra de una columna para Always Encrypted, pero no hay ninguna cuenta de Azure vinculada disponible. Agregue una cuenta de Azure vinculada y vuelva a intentar realizar la consulta."
		},
		"dist/hdfs/hdfsModel": {
			"mssql.recursivePermissionOpError": "Error al aplicar los cambios de permisos: {0}",
			"mssql.recursivePermissionOpProgress": "Aplicando cambios de permisos a \"{0}\".",
			"mssql.recursivePermissionOpStarted": "Aplicando cambios de permisos de forma recursiva en \"{0}\"",
			"mssql.recursivePermissionOpSucceeded": "Los cambios de permisos se aplicaron correctamente."
		},
		"dist/hdfs/webhdfs": {
			"webhdfs.httpError400": "Solicitud incorrecta",
			"webhdfs.httpError401": "No autorizado",
			"webhdfs.httpError403": "Prohibido",
			"webhdfs.httpError404": "No encontrado",
			"webhdfs.httpError500": "Error interno del servidor",
			"webhdfs.invalidDataStructure": "Estructura de datos no válida",
			"webhdfs.missingProperties": "No se ha podido crear el cliente de WebHDFS debido a que faltan opciones: ${0}",
			"webhdfs.undefinedArgument": "\"${0}\" no se ha definido.",
			"webhdfs.unexpectedRedirect": "Redirección inesperada",
			"webhdfs.unknownError": "Error desconocido"
		},
		"dist/localizedConstants": {
			"msgMissingNodeContext": "Se ha llamado al comando de nodo sin pasar ningún nodo",
			"mssql.accessHeader": "Acceso",
			"mssql.addLabel": "Agregar",
			"mssql.addUserOrGroup": "Agregar usuario o grupo",
			"mssql.apply": "Aplicar",
			"mssql.applyRecursively": "Aplicar recursivamente",
			"mssql.defaultHeader": "Predeterminado",
			"mssql.defaultUserAndGroups": "Usuario y grupos predeterminados",
			"mssql.delete": "Eliminar",
			"mssql.enterNamePlaceholder": "Escriba el nombre",
			"mssql.errorApplyingAclChanges": "Error inesperado al aplicar los cambios: {0}",
			"mssql.everyone": "Todos los demás",
			"mssql.executeHeader": "Ejecutar",
			"mssql.group": "Grupo",
			"mssql.groupLabel": "Agrupar",
			"mssql.inheritDefaultsLabel": "Heredar valores predeterminados",
			"mssql.locationTitle": "Ubicación: ",
			"mssql.manageAccessTitle": "Administrar el acceso",
			"mssql.namedUsersAndGroups": "Usuarios y grupos designados",
			"mssql.owner": "Propietario",
			"mssql.ownerPostfix": " - Propietario",
			"mssql.owningGroupPostfix": " - Grupo propietario",
			"mssql.permissionsTitle": "Permisos",
			"mssql.readHeader": "Leer",
			"mssql.stickyHeader": "Sticky Bit",
			"mssql.userLabel": "Usuario",
			"mssql.userOrGroupIcon": "Icono de usuario o grupo",
			"mssql.writeHeader": "Escribir",
			"sparkConnectionRequired": "Conéctese al clúster de Spark para poder ver el historial de {0}.",
			"sparkJobSubmission.GetApplicationIdFailed": "Error al obtener el identificador de aplicación. {0}",
			"sparkJobSubmission.LocalFileDestinationHint": "El archivo local se cargará en HDFS. ",
			"sparkJobSubmission.LocalFileNotExisted": "No existe el archivo local {0}. ",
			"sparkJobSubmission.NoSqlBigDataClusterFound": "No se ha encontrado ningún clúster de macrodatos de SQL Server.",
			"sparkJobSubmission.PrepareSubmitJob": "Se está enviando el trabajo \"{0}\"... ",
			"sparkJobSubmission.PrepareUploadingFile": "Carga de archivo desde {0} local a la carpeta HDFS: {1}",
			"sparkJobSubmission.SparkHistoryLinkMessage": "Url del historial de Spark: {0} ",
			"sparkJobSubmission.SubmissionEndMessage": ".......................... Final del envío del trabajo de Spark ............................",
			"sparkJobSubmission.SubmitJobFailed": "Error en el envío del trabajo de Spark. {0} ",
			"sparkJobSubmission.SubmitJobFinished": "Se ha enviado el trabajo de Spark.",
			"sparkJobSubmission.UploadingFileFailed": "Error al cargar el archivo en el clúster. {0}",
			"sparkJobSubmission.UploadingFileSucceeded": "La carga del archivo al clúster se completó correctamente",
			"sparkJobSubmission.YarnUIMessage": "URL de YarnUI: {0} "
		},
		"dist/main": {
			"msgSampleCodeDataFrame": "Este código de ejemplo carga el archivo en un marco de datos y muestra los primeros 10 resultados.",
			"mssql.errorConvertingToNotebook": "Error al convertir el documento de SQL a Notebook; {0}.",
			"mssql.errorConvertingToSQL": "Error al convertir el documento de Notebook a SQL; {0}.",
			"noController": "No se encuentra el punto de conexión del controlador para esta instancia.",
			"notebookFileType": "Notebooks",
			"unsupportedFileType": "Solo se admiten los Notebooks de tipo .ipynb"
		},
		"dist/objectExplorerNodeProvider/cancelableStream": {
			"streamCanceled": "Operación de transmisión cancelada por el usuario"
		},
		"dist/objectExplorerNodeProvider/command": {
			"cancel": "¿Cancelar operación?",
			"cancelTooltip": "Cancelar",
			"mssql.searchServers": "Buscar nombres de servidor",
			"progress": "$(sync~spin) {0}..."
		},
		"dist/objectExplorerNodeProvider/connection": {
			"connectionInfoOptionsMissingProperties": "Faltan algunas propiedades en connectionInfo.options: {0}",
			"connectionInfoOptionsUndefined": "ConnectionInfo.options no está definido.",
			"connectionInfoUndefined": "ConnectionInfo no está definido."
		},
		"dist/objectExplorerNodeProvider/fileSources": {
			"maxSizeNotice": "AVISO: Este archivo se ha truncado en {0} para la vista previa. ",
			"maxSizeReached": "El archivo se ha truncado en {0} para la vista previa."
		},
		"dist/objectExplorerNodeProvider/hdfsCommands": {
			"allFiles": "Todos los archivos",
			"copyPathError": "Error en la copia de la ruta de acceso: {0}",
			"deleteError": "Error en la eliminación de archivos: {0}",
			"enterDirName": "Introduzca el nombre del directorio",
			"lblUploadFiles": "Cargar",
			"makingDir": "Creando directorio",
			"manageAccessError": "Error inesperado al abrir el cuadro de diálogo Administrar acceso: {0}",
			"mkDirError": "Error al crear el directorio: {0}",
			"mkdirCanceled": "La operación se canceló",
			"msgDeleteFile": "¿Seguro que desea eliminar este archivo?",
			"msgDeleteFolder": "¿Seguro que desea eliminar esta carpeta y su contenido?",
			"previewError": "Error en la previsualización del archivo: {0}",
			"previewing": "Generación de vista previa",
			"saveCanceled": "Se canceló la operación de guardar",
			"saveError": "Error al guardar el archivo: {0}",
			"saving": "Guardando archivos HDFS",
			"uploadCanceled": "Se canceló la operación de carga",
			"uploadError": "Error al cargar los archivos: {0}",
			"uploading": "Cargando archivos en HDFS"
		},
		"dist/objectExplorerNodeProvider/hdfsProvider": {
			"errDeleteConnectionNode": "No se puede eliminar una conexión. Solo se pueden eliminar subcarpetas y archivos.",
			"errorExpanding": "Error: {0}"
		},
		"dist/objectExplorerNodeProvider/objectExplorerNodeProvider": {
			"hdfsFolder": "HDFS",
			"notifyError": "Error al notificar el cambio de nodo: {0}",
			"prmptPwd": "Proporcione la contraseña para conectarse a HDFS:",
			"promptUsername": "Proporcione el nombre de usuario para conectarse a HDFS:",
			"rootLabel": "Raíz",
			"sessionNotFound": "La sesión para el nodo {0} no existe"
		},
		"dist/prompts/confirm": {
			"msgNo": "No",
			"msgYes": "Sí"
		},
		"dist/sparkFeature/dialog/dialogCommands": {
			"errorNotSqlBigDataCluster": "El servidor seleccionado no pertenece a un clúster de macrodatos de SQL Server",
			"selectOtherServer": "Seleccionar otro servidor SQL Server",
			"sparkJobSubmission.GetFilePathFromSelectedNodeFailed": "Error al obtener la ruta de acceso del archivo: {0}",
			"sparkJobSubmission.NoSqlSelected": "No hay ningún servidor SQL Server seleccionado.",
			"sparkJobSubmission.PleaseSelectSqlWithCluster": "Seleccione SQL Server con un clúster de macrodatos."
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkAdvancedTab": {
			"sparkJobSubmission.AdvancedTabName": "OPCIONES AVANZADAS",
			"sparkJobSubmission.ReferenceFilesList": "Archivos de referencia",
			"sparkJobSubmission.ReferenceFilesListTooltip": "Archivos que se colocarán en el directorio de trabajo del ejecutor. La ruta de acceso del archivo debe ser una ruta de acceso HDFS. Varias rutas deben separarse por punto y coma (;)",
			"sparkJobSubmission.ReferenceJarList": "Archivos JAR de referencia",
			"sparkJobSubmission.ReferenceJarListToolTip": "Archivos JAR que se colocarán en el directorio de trabajo del ejecutor. La ruta de acceso del archivo JAR debe ser una ruta de acceso de HDFS. Varias rutas deben dividirse por punto y coma (;)",
			"sparkJobSubmission.ReferencePyList": "Archivos py de referencia",
			"sparkJobSubmission.ReferencePyListTooltip": "Archivos py que se colocarán en el directorio de trabajo del ejecutor. La ruta de acceso del archivo debe ser una ruta de acceso de HDFS. Varias rutas deben separarse por punto y coma (;)",
			"sparkJobSubmission.configValues": "Valores de configuración",
			"sparkJobSubmission.configValuesTooltip": "Lista de pares nombre-valor que contienen valores de configuración de Spark, codificados como diccionario JSON. Ejemplo: \"{'nombre':'valor', 'nombre2':'valor2'}\".",
			"sparkJobSubmission.driverCores": "Núcleos del controlador",
			"sparkJobSubmission.driverCoresTooltip": "Cantidad de núcleos de CPU que se asignarán al controlador.",
			"sparkJobSubmission.driverMemory": "Memoria de controlador",
			"sparkJobSubmission.driverMemoryTooltip": "Cantidad de memoria que se asignará al controlador. Especifique unidades como parte del valor, por ejemplo, 512 M o 2 G.",
			"sparkJobSubmission.executorCores": "Núcleos del ejecutor",
			"sparkJobSubmission.executorCoresTooltip": "Cantidad de núcleos de CPU que se asignarán al ejecutor.",
			"sparkJobSubmission.executorCount": "Recuento de ejecutores",
			"sparkJobSubmission.executorCountTooltip": "Número de instancias del ejecutor para ejecutar.",
			"sparkJobSubmission.executorMemory": "Memoria del ejecutor",
			"sparkJobSubmission.executorMemoryTooltip": "Cantidad de memoria que se asignará al ejecutor. Especifique unidades como parte del valor, por ejemplo, 512 M o 2 G.",
			"sparkJobSubmission.queueName": "Nombre de la cola",
			"sparkJobSubmission.queueNameTooltip": "Nombre de la cola de Spark en la que se va a ejecutar la sesión."
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkConfigurationTab": {
			"sparkJobSubmission.Arguments": "Argumentos",
			"sparkJobSubmission.ArgumentsTooltip": "Argumentos de línea de comandos utilizados en la clase principal, varios argumentos deben dividirse con un espacio.",
			"sparkJobSubmission.FilePathPlaceHolder": "Ruta de acceso a un archivo .jar o .py",
			"sparkJobSubmission.GeneralTabName": "GENERAL",
			"sparkJobSubmission.HDFSFileNotExisted": "El archivo HDFS especificado no existe. ",
			"sparkJobSubmission.HDFSFileNotExistedWithPath": "{0} no existe en el clúster o en la excepción iniciada. ",
			"sparkJobSubmission.JobName": "Nombre del trabajo",
			"sparkJobSubmission.JobNamePlaceHolder": "Escriba un nombre...",
			"sparkJobSubmission.LocalFileDestinationHintWithPath": "El archivo local seleccionado se cargará en HDFS: {0}",
			"sparkJobSubmission.MainClass": "Clase principal",
			"sparkJobSubmission.MainFilePath": "Archivo JAR/py",
			"sparkJobSubmission.NotSpecifyJARPYPath": "No se especifica el archivo JAR/py de la propiedad.",
			"sparkJobSubmission.NotSpecifyJobName": "No se especifica el nombre del trabajo de propiedad.",
			"sparkJobSubmission.NotSpecifyMainClass": "No se especifica la clase principal de la propiedad.",
			"sparkJobSubmission.SelectFileError": "Error al ubicar el archivo debido a un error: {0}",
			"sparkJobSubmission.SparkCluster": "Clúster de Spark",
			"sparkSelectLocalFile": "Seleccionar"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionDialog": {
			"sparkJobSubmission.DialogCancelButton": "Cancelar",
			"sparkJobSubmission.DialogSubmitButton": "Enviar",
			"sparkJobSubmission.DialogTitleNewJob": "Nuevo trabajo",
			"sparkJobSubmission.SparkJobSubmissionDialogInitializeError": "Los parámetros de SparkJobSubmissionDialog no son válidos",
			"sparkJobSubmission.SubmissionStartMessage": ".......................... Inicio del envío del trabajo de Spark ..........................",
			"sparkJobSubmission.SubmitSparkJob": "Envío de trabajo de Spark {0}:"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionModel": {
			"sparkJobSubmission.GetApplicationIdTimeOut": "Obtener tiempo de espera del identificador de aplicación. {0}[Registro]   {1}",
			"sparkJobSubmission.LivyBatchIdIsInvalid": "El elemento livyBatchId no es válido. ",
			"sparkJobSubmission.PathNotSpecified.": "No se especifica la ruta de acceso de la propiedad. ",
			"sparkJobSubmission.SparkJobSubmissionModelInitializeError": "Los parámetros de SparkJobSubmissionModel no son válidos",
			"sparkJobSubmission.localFileOrFolderNotSpecified.": "No se especifica la propiedad localFilePath o hdfsFolderPath. ",
			"sparkJobSubmission.submissionArgsIsInvalid": "El elemento submissionArgs no es válido. "
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionService": {
			"sparkJobSubmission.LivyNoBatchIdReturned": "No se devuelve ningún identificador de lote de trabajo de Spark de la respuesta. {0}[Error] {1}",
			"sparkJobSubmission.LivyNoLogReturned": "No se devuelve ningún registro dentro de la respuesta.{0}[Error] {1}"
		},
		"dist/sqlClusterLookUp": {
			"bdcConnectError": "Error: {0}.",
			"promptBDCPassword": "Proporcione la contraseña para conectarse al controlador de BDC.",
			"promptBDCUsername": "{0}Especifique el nombre de usuario para conectarse al controlador de BDC:",
			"usernameAndPasswordRequired": "Es necesario especificar el nombre de usuario y la contraseña."
		},
		"dist/sqlToolsServer": {
			"downloadServiceDoneChannelMsg": "Instalación terminada {0}",
			"downloadingServiceChannelMsg": "Descargando {0}",
			"downloadingServiceSizeChannelMsg": "({0} KB)",
			"downloadingServiceStatusMsg": "Descargando {0}",
			"entryExtractedChannelMsg": "Elementos extraídos: {0} ({1} de {2})",
			"failedToStartServiceErrorMsg": "No se ha podido iniciar {0}",
			"installedServiceChannelMsg": "{0} instalado",
			"installingServiceChannelMsg": "Instalando {0} en {1}",
			"installingServiceStatusMsg": "Instalando {0}",
			"serviceStartedStatusMsg": "{0} iniciado",
			"startingServiceStatusMsg": "Iniciando {0}"
		},
		"dist/telemetry": {
			"serviceCrashMessage": "El componente {0} se cerró de forma inesperada. Reinicie Azure Data Studio.",
			"viewKnownIssuesText": "Ver problemas conocidos"
		},
		"package": {
			"cloud.databaseProperties.azureEdition": "Edición",
			"cloud.databaseProperties.compatibilityLevel": "Nivel de compatibilidad",
			"cloud.databaseProperties.owner": "Propietario",
			"cloud.databaseProperties.serviceLevelObjective": "Plan de tarifa",
			"cloud.serverProperties.serverEdition": "Tipo",
			"cloud.serverProperties.serverVersion": "Versión",
			"databasesListProperties.lastBackup": "Última copia de seguridad",
			"databasesListProperties.name": "Nombre",
			"databasesListProperties.size": "Tamaño (MB)",
			"databasesListProperties.status": "Estado",
			"json.format.enable.desc": "Habilitar/deshabilitar formateador JSON predeterminado (requiere reiniciar)",
			"json.schemas.desc": "Asociar esquemas a archivos JSON en el proyecto actual",
			"json.schemas.fileMatch.desc": "Una matriz de patrones de archivo con los cuales coincidir cuando los archivos JSON se resuelvan en esquemas.",
			"json.schemas.fileMatch.item.desc": "Un patrón de archivo que puede contener \"*\" con el cual coincidir cuando los archivos JSON se resuelvan en esquemas.",
			"json.schemas.schema.desc": "La definición de esquema de la dirección URL determinada. Solo se necesita proporcionar el esquema para evitar los accesos a la dirección URL del esquema.",
			"json.schemas.url.desc": "Una dirección URL a un esquema o una ruta de acceso relativa a un esquema en el directorio actual",
			"mssql.configuration.title": "Configuración de MSSQL",
			"mssql.connectionOptions.applicationIntent.description": "Declara el tipo de carga de trabajo de la aplicación al conectarse a un servidor",
			"mssql.connectionOptions.applicationIntent.displayName": "Intención de la aplicación",
			"mssql.connectionOptions.applicationName.description": "El nombre de la aplicación",
			"mssql.connectionOptions.applicationName.displayName": "Nombre de la aplicación",
			"mssql.connectionOptions.asynchronousProcessing.description": "Cuando es true, habilita el uso de la funcionalidad asincrónica en el proveedor de datos de .NET Framework",
			"mssql.connectionOptions.asynchronousProcessing.displayName": "Procesamiento asincrónico",
			"mssql.connectionOptions.attachDbFilename.displayName": "Adjuntar nombre de archivo de base de datos",
			"mssql.connectionOptions.attachedDBFileName.description": "Nombre del archivo principal, incluido el nombre completo de ruta, de una base de datos que se puede adjuntar",
			"mssql.connectionOptions.attachedDBFileName.displayName": "Nombre del archivo de base de datos adjunto",
			"mssql.connectionOptions.authType.categoryValues.azureMFA": "Azure Active Directory: universal con compatibilidad con MFA",
			"mssql.connectionOptions.authType.categoryValues.integrated": "Autenticación de Windows",
			"mssql.connectionOptions.authType.categoryValues.sqlLogin": "Inicio de sesión SQL",
			"mssql.connectionOptions.authType.description": "Especifica el método de autenticación con SQL Server",
			"mssql.connectionOptions.authType.displayName": "Tipo de autenticación",
			"mssql.connectionOptions.columnEncryptionSetting.description": "Habilita o deshabilita Always Encrypted para la conexión.",
			"mssql.connectionOptions.columnEncryptionSetting.displayName": "Always Encrypted",
			"mssql.connectionOptions.connectRetryCount.description": "Número de intentos para restaurar la conexión",
			"mssql.connectionOptions.connectRetryCount.displayName": "Recuento de reintentos de conexión",
			"mssql.connectionOptions.connectRetryInterval.description": "Retraso entre intentos para restaurar la conexión",
			"mssql.connectionOptions.connectRetryInterval.displayName": "Intervalo de reintento de conexión",
			"mssql.connectionOptions.connectTimeout.description": "Intervalo de tiempo (en segundos) que se debe esperar a que se establezca la conexión con el servidor antes de dejar de intentarlo y generar un error",
			"mssql.connectionOptions.connectTimeout.displayName": "Tiempo de espera de la conexión",
			"mssql.connectionOptions.connectionName.description": "Nombre personalizado de la conexión",
			"mssql.connectionOptions.connectionName.displayName": "Nombre (opcional)",
			"mssql.connectionOptions.contextConnection.description": "Cuando es true, indica que la conexión debe ser desde el contexto de SQL Server. Disponible sólo cuando se ejecuta en el proceso de SQL Server",
			"mssql.connectionOptions.contextConnection.displayName": "Conexión contextual",
			"mssql.connectionOptions.currentLanguage.description": "El nombre del registro de idioma de SQL Server",
			"mssql.connectionOptions.currentLanguage.displayName": "Idioma actual",
			"mssql.connectionOptions.databaseName.description": "Nombre del catálogo o base de datos inicial del origen de datos",
			"mssql.connectionOptions.databaseName.displayName": "Base de datos",
			"mssql.connectionOptions.enclaveAttestationProtocol.categoryValues.AAS": "Atestación de Azure",
			"mssql.connectionOptions.enclaveAttestationProtocol.categoryValues.HGS": "Servicio de protección de host",
			"mssql.connectionOptions.enclaveAttestationProtocol.description": "Especifica un protocolo para la atestación de un enclave de servidor empleado con Always Encrypted con enclaves seguros.",
			"mssql.connectionOptions.enclaveAttestationProtocol.displayName": "Protocolo de atestación",
			"mssql.connectionOptions.enclaveAttestationUrl.description": "Especifica un punto de conexión para la atestación de un enclave de servidor empleado con Always Encrypted con enclaves seguros.",
			"mssql.connectionOptions.enclaveAttestationUrl.displayName": "Dirección URL de atestación del enclave",
			"mssql.connectionOptions.encrypt.description": "Cuando el valor es true, SQL Server utiliza cifrado SSL para todos los datos enviados entre el cliente y el servidor, cuando el servidor tiene instalado un certificado",
			"mssql.connectionOptions.encrypt.displayName": "Cifrar",
			"mssql.connectionOptions.failoverPartner.description": "El nombre o la dirección de red de la instancia de SQL Server que actúa como asociado para la conmutación por error",
			"mssql.connectionOptions.failoverPartner.displayName": "Socio de conmutación por error",
			"mssql.connectionOptions.groupName.advanced": "Opciones avanzadas",
			"mssql.connectionOptions.groupName.connectionResiliency": "Resistencia de la conexión",
			"mssql.connectionOptions.groupName.context": "Contexto",
			"mssql.connectionOptions.groupName.initialization": "Inicialización",
			"mssql.connectionOptions.groupName.pooling": "Agrupación",
			"mssql.connectionOptions.groupName.replication": "Replicación",
			"mssql.connectionOptions.groupName.security": "Seguridad",
			"mssql.connectionOptions.groupName.source": "Origen",
			"mssql.connectionOptions.loadBalanceTimeout.description": "Periodo mínimo de tiempo (en segundos) que residirá esta conexión en el grupo antes de que se destruya",
			"mssql.connectionOptions.loadBalanceTimeout.displayName": "Tiempo de espera del equilibrio de carga",
			"mssql.connectionOptions.maxPoolSize.description": "El número máximo de conexiones permitidas en el grupo",
			"mssql.connectionOptions.maxPoolSize.displayName": "Tamaño máximo del grupo",
			"mssql.connectionOptions.minPoolSize.description": "El número mínimo de conexiones permitidas en el grupo",
			"mssql.connectionOptions.minPoolSize.displayName": "Tamaño mínimo del grupo",
			"mssql.connectionOptions.multiSubnetFailover.displayName": "Conmutación por error de varias subredes",
			"mssql.connectionOptions.multipleActiveResultSets.description": "Cuando el valor es true, se pueden devolver varios conjuntos de resultados y leerlos desde una conexión.",
			"mssql.connectionOptions.multipleActiveResultSets.displayName": "Conjuntos de resultados activos múltiples (MARS)",
			"mssql.connectionOptions.packetSize.description": "Tamaño en bytes de los paquetes de red utilizados para comunicarse con una instancia de SQL Server",
			"mssql.connectionOptions.packetSize.displayName": "Tamaño del paquete",
			"mssql.connectionOptions.password.description": "Indica la contraseña que se utilizará al conectarse al origen de datos",
			"mssql.connectionOptions.password.displayName": "Contraseña",
			"mssql.connectionOptions.persistSecurityInfo.description": "Si el valor es false, no se devuelve información confidencial de seguridad, como la contraseña, como parte de la conexión",
			"mssql.connectionOptions.persistSecurityInfo.displayName": "Información de seguridad persistente",
			"mssql.connectionOptions.pooling.description": "Cuando el valor es true, el objeto de conexión se obtiene del grupo apropiado, o si es necesario, se crea y agrega al grupo apropiado",
			"mssql.connectionOptions.pooling.displayName": "Agrupación",
			"mssql.connectionOptions.port.displayName": "Puerto",
			"mssql.connectionOptions.replication.description": "Utilizado por SQL Server en replicación",
			"mssql.connectionOptions.replication.displayName": "Replicación",
			"mssql.connectionOptions.serverName.description": "Nombre de la instancia de SQL Server",
			"mssql.connectionOptions.serverName.displayName": "Servidor",
			"mssql.connectionOptions.trustServerCertificate.description": "Cuando es true (y encrypt=true), SQL Server usa el cifrado SSL para todos los datos enviados entre el cliente y el servidor sin validar el certificado del servidor",
			"mssql.connectionOptions.trustServerCertificate.displayName": "Certificado de servidor de confianza",
			"mssql.connectionOptions.typeSystemVersion.description": "Indica qué sistema de tipo de servidor el proveedor expondrá por medio de DataReader.",
			"mssql.connectionOptions.typeSystemVersion.displayName": "Versión de sistema de tipo",
			"mssql.connectionOptions.userName.description": "Indica el identificador de usuario que se va a usar al conectar con el origen de datos",
			"mssql.connectionOptions.userName.displayName": "Nombre del usuario",
			"mssql.connectionOptions.workstationId.description": "El nombre de la estación de trabajo que se conecta a SQL Server",
			"mssql.connectionOptions.workstationId.displayName": "Id. de estación de trabajo",
			"mssql.disabled": "Deshabilitado",
			"mssql.enabled": "Habilitado",
			"mssql.exportNotebookToSql": "Exportar cuaderno como SQL",
			"mssql.exportSqlAsNotebook": "Exportar SQL como cuaderno",
			"mssql.format.alignColumnDefinitionsInColumns": "Indica si las definiciones de columna deben alinearse.",
			"mssql.format.datatypeCasing": "Indica si los tipos de datos deben formatearse como MAYÚSCULAS, minúsculas o nada (sin formato).",
			"mssql.format.keywordCasing": "Indica si las palabras clave deben formatearse como MAYÚSCULAS, minúsculas o nada (sin formato).",
			"mssql.format.placeCommasBeforeNextStatement": "Indica si las comas deben colocarse al principio de cada instrucción de una lista por ejemplo, \", micolumna2\" en lugar de al final, por ejemplo, \"micolumna1,\".",
			"mssql.format.placeSelectStatementReferencesOnNewLine": "¿Deben separarse en líneas distintas las referencias a objetos de las instrucciones select? Por ejemplo, en \"SELECT C1, C2 FROM T1\", C1 y C2 estarán en líneas separadas",
			"mssql.ignorePlatformWarning": "[Opcional] No mostrar advertencias de plataformas no compatibles",
			"mssql.intelliSense.enableErrorChecking": "Indica si debe habilitarse la comprobación de errores de IntelliSense.",
			"mssql.intelliSense.enableIntelliSense": "Indica si debe habilitarse IntelliSense.",
			"mssql.intelliSense.enableQuickInfo": "Indica si debe habilitarse la información rápida de IntelliSense.",
			"mssql.intelliSense.enableSuggestions": "Indica si deben habilitarse las sugerencias de IntelliSense.",
			"mssql.intelliSense.lowerCaseSuggestions": "Indica si las sugerencias de IntelliSense deben estar en minúsculas.",
			"mssql.logDebugInfo": "[Opcional] Registre la salida de depuración en a la consola (Ver -> Salida) y después seleccione el canal de salida apropiado del menú desplegable",
			"mssql.logFilesRemovalLimit": "Número máximo de archivos antiguos para quitarse en el inicio que tienen expirado el valor mssql.logRetentionMinutes. Los archivos que no se limpien debido a esta limitación se limpiarán la próxima vez que se inicie Azure Data Studio.",
			"mssql.logRetentionMinutes": "Número de minutos para conservar los archivos de registro para los servicios back-end. El valor predeterminado es 1 semana.",
			"mssql.provider.displayName": "Microsoft SQL Server",
			"mssql.query.alwaysEncryptedParameterization": "Habilitar parametrización de Always Encrypted",
			"mssql.query.ansiDefaults": "Habilitar SET ANSI_DEFAULTS",
			"mssql.query.ansiNullDefaultOn": "Habilitar SET ANSI_NULL_DFLT_ON",
			"mssql.query.ansiNulls": "Habilitar SET ANSI_NULLS",
			"mssql.query.ansiPadding": "Habilitar SET ANSI_PADDING",
			"mssql.query.ansiWarnings": "Habilitar SET ANSI_WARNINGS",
			"mssql.query.arithAbort": "Habilitar la opción SET ARITHABORT",
			"mssql.query.cursorCloseOnCommit": "Habilitar SET CURSOR_CLOSE_ON_COMMIT",
			"mssql.query.deadlockPriority": "Habilitar la opción SET DEADLOCK_PRIORITY",
			"mssql.query.displayBitAsNumber": "¿Deben mostrarse las columnas BIT como números (1 o 0)? Si es false, las columnas BIT se mostrarán como \"true\" o \"false\".",
			"mssql.query.executionTimeout": "Un tiempo de espera de ejecución de 0 indica una espera ilimitada (sin tiempo de espera)",
			"mssql.query.implicitTransactions": "Habilitar SET IMPLICIT_TRANSACTIONS",
			"mssql.query.lockTimeout": "Habilitar la opción SET LOCK TIMEOUT (en milisegundos)",
			"mssql.query.maxXmlCharsToStore": "Número de caracteres XML que se almacenarán después de ejecutar una consulta.",
			"mssql.query.noCount": "Habilitar la opción SET NOCOUNT",
			"mssql.query.noExec": "Habilitar la opción SET NOEXEC",
			"mssql.query.parseOnly": "Habilitar la opción SET PARSEONLY",
			"mssql.query.queryGovernorCostLimit": "Habilitar SET QUERY_GOVERNOR_COST_LIMIT",
			"mssql.query.quotedIdentifier": "Habilitar SET QUOTED_IDENTIFIER",
			"mssql.query.setRowCount": "Número máximo de filas para devolver antes de que el servidor deje de procesar la consulta.",
			"mssql.query.statisticsIO": "Habilitar la opción SET STATISTICS IO",
			"mssql.query.statisticsTime": "Habilitar la opción SET STATISTICS TIME",
			"mssql.query.textSize": "Tamaño máximo del texto y datos de ntext devueltos por una instrucción SELECT",
			"mssql.query.transactionIsolationLevel": "Habilitar la opción SET TRANSACTION ISOLATION LEVEL",
			"mssql.query.xactAbortOn": "Habilitar la opción SET XACT_ABORT ON",
			"mssql.tracingLevel": "[Opcional] El nivel de registro para servicios back-end. Azure Data Studio genera un nombre de archivo cada vez que se inicia y, si el archivo ya existe, las entradas de registros se anexan a ese archivo. Para la limpieza de archivos de registro antiguos, consulte la configuración de logRetentionMinutes y logFilesRemovalLimit. El valor predeterminado tracingLevel no registra mucho. El cambio de detalle podría dar lugar a amplios requisitos de registro y espacio en disco para los registros. Error incluye Crítico, Advertencia incluye Error, Información incluye Advertencia y Detallado incluye Información.",
			"mssqlCluster.copyPath": "Copiar ruta de acceso",
			"mssqlCluster.deleteFiles": "Eliminar",
			"mssqlCluster.manageAccess": "Administrar el acceso",
			"mssqlCluster.mkdir": "Nuevo directorio",
			"mssqlCluster.previewFile": "Versión preliminar",
			"mssqlCluster.saveFile": "Guardar",
			"mssqlCluster.uploadFiles": "Cargar archivos",
			"notebook.command.new": "Nuevo Notebook",
			"notebook.command.open": "Abrir Notebook",
			"objectsListProperties.name": "Nombre",
			"onprem.databaseProperties.compatibilityLevel": "Nivel de compatibilidad",
			"onprem.databaseProperties.lastBackupDate": "Última copia de seguridad de la base de datos",
			"onprem.databaseProperties.lastLogBackupDate": "Última copia de seguridad de registros",
			"onprem.databaseProperties.owner": "Propietario",
			"onprem.databaseProperties.recoveryModel": "Modelo de recuperación",
			"onprem.serverProperties.machineName": "Nombre del equipo",
			"onprem.serverProperties.osVersion": "Versión del sistema operativo",
			"onprem.serverProperties.serverEdition": "Edición",
			"onprem.serverProperties.serverVersion": "Versión",
			"tab.bigDataClusterDescription": "Tareas e información sobre el clúster de macrodatos de SQL Server",
			"title.bigDataCluster": "Clúster de macrodatos de SQL Server",
			"title.books": "Notebooks",
			"title.clearSearchServerResult": "Buscar: Borrar los resultados del servidor de búsqueda",
			"title.configurePython": "Configurar Python para Notebooks",
			"title.designTable": "Diseño",
			"title.endpoints": "Puntos de conexión de servicio",
			"title.installPackages": "Instalar paquetes",
			"title.newSparkJob": "Nuevo trabajo de Spark",
			"title.newTable": "Nueva tabla",
			"title.openClusterDashboard": "Panel del\r\nclúster",
			"title.openSparkHistory": "Ver el historial de Spark",
			"title.openYarnHistory": "Ver historial de Yarn",
			"title.searchServers": "Buscar: Servidores",
			"title.showLogFile": "Mostrar archivo de registro",
			"title.submitSparkJob": "Enviar trabajo de Spark",
			"title.tasks": "Tareas"
		}
	}
}