{
	"": [
		"--------------------------------------------------------------------------------------------",
		"Copyright (c) Microsoft Corporation. All rights reserved.",
		"Licensed under the Source EULA. See License.txt in the project root for license information.",
		"--------------------------------------------------------------------------------------------",
		"Do not edit this file. It is machine generated."
	],
	"version": "1.0.0",
	"contents": {
		"dist/dashboard/serviceEndpoints": {
			"copyText": "Copia",
			"endpoint.appproxy": "Proxy dell'applicazione",
			"endpoint.controller": "Servizio di gestione cluster",
			"endpoint.gateway": "Gateway per l'accesso ai file HDFS, Spark",
			"endpoint.grafana": "Dashboard di metriche",
			"endpoint.kibana": "Dashboard di ricerca log",
			"endpoint.livy": "Proxy per l'esecuzione di istruzioni, processi e applicazioni Spark",
			"endpoint.managementproxy": "Proxy di gestione",
			"endpoint.mgmtproxy": "Proxy di gestione",
			"endpoint.sparkHistory": "Dashboard di gestione processi e monitoraggio di Spark",
			"endpoint.sqlServerEndpoint": "Front-end dell'istanza master di SQL Server",
			"endpoint.webhdfs": "Proxy del file system HDFS",
			"endpoint.yarnHistory": "Dashboard di diagnostica e monitoraggio di Spark",
			"grafana": "Dashboard di metriche",
			"kibana": "Dashboard di ricerca log",
			"sparkHistory": "Dashboard di gestione processi e monitoraggio di Spark",
			"yarnHistory": "Dashboard di diagnostica e monitoraggio di Spark"
		},
		"dist/features": {
			"mssql.canceledLinkedAzureAccountSelection": "Azure Data Studio deve contattare Azure Key Vault per accedere a una chiave master di colonna per Always Encrypted, ma non è stato selezionato alcun account Azure collegato. Ripetere la query e selezionare un account Azure collegato quando richiesto.",
			"mssql.chooseLinkedAzureAccount": "Selezionare un account Azure collegato:",
			"mssql.insufficientlyPrivelagedAzureAccount": "L'account Azure configurato per {0} non ha autorizzazioni sufficienti per Azure Key Vault per accedere alla chiave master di colonna per Always Encrypted.",
			"mssql.missingLinkedAzureAccount": "Azure Data Studio deve contattare Azure Key Vault per accedere a una chiave master di colonna per Always Encrypted, ma non è disponibile alcun account Azure collegato. Aggiungere un account Azure collegato e ripetere la query."
		},
		"dist/hdfs/hdfsModel": {
			"mssql.recursivePermissionOpError": "Si è verificato un errore durante l'applicazione delle modifiche delle autorizzazioni: {0}",
			"mssql.recursivePermissionOpProgress": "Applicazione delle modifiche delle autorizzazioni a '{0}'.",
			"mssql.recursivePermissionOpStarted": "Applicazione delle modifiche delle autorizzazioni in modo ricorsivo in '{0}'",
			"mssql.recursivePermissionOpSucceeded": "Le modifiche delle autorizzazioni sono state applicate."
		},
		"dist/hdfs/webhdfs": {
			"webhdfs.httpError400": "Richiesta non valida",
			"webhdfs.httpError401": "Non autorizzato",
			"webhdfs.httpError403": "Accesso negato",
			"webhdfs.httpError404": "Non trovato",
			"webhdfs.httpError500": "Errore interno del server",
			"webhdfs.invalidDataStructure": "Struttura dei dati non valida",
			"webhdfs.missingProperties": "Non è possibile creare il client WebHDFS a causa di opzioni mancanti: ${0}",
			"webhdfs.undefinedArgument": "'${0}' non è definito.",
			"webhdfs.unexpectedRedirect": "Reindirizzamento imprevisto",
			"webhdfs.unknownError": "Errore sconosciuto"
		},
		"dist/localizedConstants": {
			"msgMissingNodeContext": "Il comando di Node è stato chiamato senza passare alcun nodo",
			"mssql.accessHeader": "Accesso",
			"mssql.addLabel": "Aggiungi",
			"mssql.addUserOrGroup": "Aggiungi utente o gruppo",
			"mssql.apply": "Applica",
			"mssql.applyRecursively": "Applica in modo ricorsivo",
			"mssql.defaultHeader": "Predefinito",
			"mssql.defaultUserAndGroups": "Utenti e gruppi predefiniti",
			"mssql.delete": "Elimina",
			"mssql.enterNamePlaceholder": "Immettere il nome",
			"mssql.errorApplyingAclChanges": "Si è verificato un errore imprevisto durante l'applicazione delle modifiche: {0}",
			"mssql.everyone": "Tutti gli altri",
			"mssql.executeHeader": "Esecuzione",
			"mssql.group": "Gruppo",
			"mssql.groupLabel": "Gruppo",
			"mssql.inheritDefaultsLabel": "Impostazioni predefinite di ereditarietà",
			"mssql.locationTitle": "Percorso : ",
			"mssql.manageAccessTitle": "Gestisci accesso",
			"mssql.namedUsersAndGroups": "Utenti e gruppi non anonimi",
			"mssql.owner": "Proprietario",
			"mssql.ownerPostfix": " - Proprietario",
			"mssql.owningGroupPostfix": " - Gruppo proprietario",
			"mssql.permissionsTitle": "Autorizzazioni",
			"mssql.readHeader": "Lettura",
			"mssql.stickyHeader": "Sticky bit",
			"mssql.userLabel": "Utente",
			"mssql.userOrGroupIcon": "Icona utente o gruppo",
			"mssql.writeHeader": "Scrittura",
			"sparkConnectionRequired": "Prima di visualizzare la cronologia {0}, connettersi al cluster Spark.",
			"sparkJobSubmission.GetApplicationIdFailed": "Il recupero dell'ID applicazione non è riuscito. {0}",
			"sparkJobSubmission.LocalFileDestinationHint": "Il file locale verrà caricato in HDFS. ",
			"sparkJobSubmission.LocalFileNotExisted": "Il file locale {0} non esiste. ",
			"sparkJobSubmission.NoSqlBigDataClusterFound": "Non è stato trovato alcun cluster Big Data di SQL Server.",
			"sparkJobSubmission.PrepareSubmitJob": "Invio del processo {0}... ",
			"sparkJobSubmission.PrepareUploadingFile": "Caricamento del file dalla cartella locale {0} alla cartella HDFS: {1}",
			"sparkJobSubmission.SparkHistoryLinkMessage": "URL della cronologia di Spark: {0} ",
			"sparkJobSubmission.SubmissionEndMessage": ".......................... Invia processo Spark - Fine ..........................",
			"sparkJobSubmission.SubmitJobFailed": "L'invio del processo Spark non è riuscito. {0} ",
			"sparkJobSubmission.SubmitJobFinished": "Il processo Spark è stato inviato.",
			"sparkJobSubmission.UploadingFileFailed": "Il caricamento del file nel cluster non è riuscito. {0}",
			"sparkJobSubmission.UploadingFileSucceeded": "Il caricamento del file nel cluster è riuscito.",
			"sparkJobSubmission.YarnUIMessage": "URL dell'interfaccia utente di YARN: {0} "
		},
		"dist/main": {
			"msgSampleCodeDataFrame": "Questo codice di esempio consente di caricare il file in un frame di dati e visualizzare i primi 10 risultati.",
			"mssql.errorConvertingToNotebook": "Si è verificato un errore durante la conversione del documento SQL in un notebook. Errore: {0}",
			"mssql.errorConvertingToSQL": "Si è verificato un errore durante la conversione del documento notebook in SQL. Errore: {0}",
			"noController": "Non è stato possibile trovare l'endpoint del controller per questa istanza",
			"notebookFileType": "Notebooks",
			"unsupportedFileType": "Sono supportati solo notebook con estensione ipynb"
		},
		"dist/objectExplorerNodeProvider/cancelableStream": {
			"streamCanceled": "Operazione di flusso annullata dall'utente"
		},
		"dist/objectExplorerNodeProvider/command": {
			"cancel": "Annullare l'operazione?",
			"cancelTooltip": "Annulla",
			"mssql.searchServers": "Nomi dei server di ricerca",
			"progress": "$(sync~spin) {0}..."
		},
		"dist/objectExplorerNodeProvider/connection": {
			"connectionInfoOptionsMissingProperties": "In connectionInfo.options mancano alcune proprietà: {0}",
			"connectionInfoOptionsUndefined": "ConnectionInfo.options non è definito.",
			"connectionInfoUndefined": "ConnectionInfo non è definito."
		},
		"dist/objectExplorerNodeProvider/fileSources": {
			"maxSizeNotice": "AVVISO: questo file è stato troncato alla posizione {0} per l'anteprima. ",
			"maxSizeReached": "Il file è stato troncato alla posizione {0} per l'anteprima."
		},
		"dist/objectExplorerNodeProvider/hdfsCommands": {
			"allFiles": "Tutti i file",
			"copyPathError": "Si è verificato un errore durante la copia del percorso: {0}",
			"deleteError": "Si è verificato un errore durante l'eliminazione dei file: {0}",
			"enterDirName": "Immettere il nome della directory",
			"lblUploadFiles": "Carica",
			"makingDir": "Creazione della directory",
			"manageAccessError": "Si è verificato un errore imprevisto durante l'apertura della finestra Gestisci accesso: {0}",
			"mkDirError": "Si è verificato un errore durante la creazione della directory: {0}",
			"mkdirCanceled": "L'operazione è stata annullata",
			"msgDeleteFile": "Eliminare questo file?",
			"msgDeleteFolder": "Eliminare questa cartella e il relativo contenuto?",
			"previewError": "Si è verificato un errore durante l'anteprima del file: {0}",
			"previewing": "Generazione dell'anteprima",
			"saveCanceled": "L'operazione di salvataggio è stata annullata",
			"saveError": "Si è verificato un errore durante il salvataggio del file: {0}",
			"saving": "Salvataggio dei file HDFS",
			"uploadCanceled": "L'operazione di caricamento è stata annullata",
			"uploadError": "Si è verificato un errore durante il caricamento dei file: {0}",
			"uploading": "Caricamento di file in HDFS"
		},
		"dist/objectExplorerNodeProvider/hdfsProvider": {
			"errDeleteConnectionNode": "Non è possibile eliminare una connessione. È possibile eliminare solo sottocartelle e file.",
			"errorExpanding": "Errore: {0}"
		},
		"dist/objectExplorerNodeProvider/objectExplorerNodeProvider": {
			"hdfsFolder": "HDFS",
			"notifyError": "Si è verificato un errore durante la notifica della modifica del nodo: {0}",
			"prmptPwd": "Specificare la password per la connessione a HDFS:",
			"promptUsername": "Specificare il nome utente per la connessione a HDFS:",
			"rootLabel": "Radice",
			"sessionNotFound": "La sessione per il nodo {0} non esiste"
		},
		"dist/prompts/confirm": {
			"msgNo": "No",
			"msgYes": "Sì"
		},
		"dist/sparkFeature/dialog/dialogCommands": {
			"errorNotSqlBigDataCluster": "Il server selezionato non appartiene a un cluster Big Data di SQL Server",
			"selectOtherServer": "Seleziona un'altra istanza di SQL Server",
			"sparkJobSubmission.GetFilePathFromSelectedNodeFailed": "Si è verificato un errore durante il recupero del percorso del file: {0}",
			"sparkJobSubmission.NoSqlSelected": "Non è stata selezionata alcuna istanza di SQL Server.",
			"sparkJobSubmission.PleaseSelectSqlWithCluster": "Selezionare SQL Server con il cluster Big Data."
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkAdvancedTab": {
			"sparkJobSubmission.AdvancedTabName": "AVANZATE",
			"sparkJobSubmission.ReferenceFilesList": "File di riferimento",
			"sparkJobSubmission.ReferenceFilesListTooltip": "File da inserire nella directory di lavoro dell'executor. Il percorso dei file deve essere di tipo HDFS. Separare più percorsi con punti e virgola (;)",
			"sparkJobSubmission.ReferenceJarList": "File JAR di riferimento",
			"sparkJobSubmission.ReferenceJarListToolTip": "File con estensione jar da inserire nella directory di lavoro dell'executor. Il percorso dei file deve essere di tipo HDFS. Separare più percorsi con punti e virgola (;)",
			"sparkJobSubmission.ReferencePyList": "File py di riferimento",
			"sparkJobSubmission.ReferencePyListTooltip": "File con estensione py da inserire nella directory di lavoro dell'executor. Il percorso dei file deve essere di tipo HDFS. Separare più percorsi con punti e virgola (;)",
			"sparkJobSubmission.configValues": "Valori di configurazione",
			"sparkJobSubmission.configValuesTooltip": "Elenco di coppie nome-valore contenenti valori di configurazione Spark. Codificato come dizionario JSON. Esempio: '{\"name\":\"value\", \"name2\":\"value2\"}'.",
			"sparkJobSubmission.driverCores": "Core driver",
			"sparkJobSubmission.driverCoresTooltip": "Quantità di core CPU da allocare al driver.",
			"sparkJobSubmission.driverMemory": "Memoria driver",
			"sparkJobSubmission.driverMemoryTooltip": "Quantità di memoria da allocare al driver. Specificare le unità come parte del valore. Esempio: 512 M o 2 G.",
			"sparkJobSubmission.executorCores": "Core executor",
			"sparkJobSubmission.executorCoresTooltip": "Quantità di core CPU da allocare all'executor.",
			"sparkJobSubmission.executorCount": "Conteggio executor",
			"sparkJobSubmission.executorCountTooltip": "Numero di istanze dell'executor da eseguire.",
			"sparkJobSubmission.executorMemory": "Memoria executor",
			"sparkJobSubmission.executorMemoryTooltip": "Quantità di memoria da allocare all'executor. Specificare le unità come parte del valore. Esempio: 512 M o 2 G.",
			"sparkJobSubmission.queueName": "Nome coda",
			"sparkJobSubmission.queueNameTooltip": "Nome della coda Spark in cui eseguire la sessione."
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkConfigurationTab": {
			"sparkJobSubmission.Arguments": "Argomenti",
			"sparkJobSubmission.ArgumentsTooltip": "Argomenti della riga di comando usati nella classe principale. Separare più argomenti con uno spazio.",
			"sparkJobSubmission.FilePathPlaceHolder": "Percorso di un file con estensione jar o py",
			"sparkJobSubmission.GeneralTabName": "GENERALE",
			"sparkJobSubmission.HDFSFileNotExisted": "Il file HDFS specificato non esiste. ",
			"sparkJobSubmission.HDFSFileNotExistedWithPath": "{0} non esiste nel cluster oppure è stata generata un'eccezione. ",
			"sparkJobSubmission.JobName": "Nome processo",
			"sparkJobSubmission.JobNamePlaceHolder": "Immetti un nome...",
			"sparkJobSubmission.LocalFileDestinationHintWithPath": "Il file locale selezionato verrà caricato in HDFS: {0}",
			"sparkJobSubmission.MainClass": "Classe principale",
			"sparkJobSubmission.MainFilePath": "File JAR/py",
			"sparkJobSubmission.NotSpecifyJARPYPath": "Il file JAR/py della proprietà non è specificato.",
			"sparkJobSubmission.NotSpecifyJobName": "Il nome del processo della proprietà non è specificato.",
			"sparkJobSubmission.NotSpecifyMainClass": "La classe principale della proprietà non è specificata.",
			"sparkJobSubmission.SelectFileError": "Si è verificato un errore durante l'individuazione del file. Errore: {0}",
			"sparkJobSubmission.SparkCluster": "Cluster Spark",
			"sparkSelectLocalFile": "Seleziona"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionDialog": {
			"sparkJobSubmission.DialogCancelButton": "Annulla",
			"sparkJobSubmission.DialogSubmitButton": "Invia",
			"sparkJobSubmission.DialogTitleNewJob": "Nuovo processo",
			"sparkJobSubmission.SparkJobSubmissionDialogInitializeError": "I parametri per SparkJobSubmissionDialog non sono validi",
			"sparkJobSubmission.SubmissionStartMessage": ".......................... Invia processo Spark - Inizio ..........................",
			"sparkJobSubmission.SubmitSparkJob": "Invio processo Spark {0}:"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionModel": {
			"sparkJobSubmission.GetApplicationIdTimeOut": "Timeout durante il recupero dell'ID applicazione. {0}[Log]   {1}",
			"sparkJobSubmission.LivyBatchIdIsInvalid": "livyBatchId non è valido. ",
			"sparkJobSubmission.PathNotSpecified.": "Il percorso proprietà non è specificato. ",
			"sparkJobSubmission.SparkJobSubmissionModelInitializeError": "I parametri per SparkJobSubmissionModel non sono validi",
			"sparkJobSubmission.localFileOrFolderNotSpecified.": "La proprietà localFilePath o hdfsFolderPath non è specificata. ",
			"sparkJobSubmission.submissionArgsIsInvalid": "submissionArgs non è valido. "
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionService": {
			"sparkJobSubmission.LivyNoBatchIdReturned": "La risposta non ha restituito alcun ID batch di processo Spark.{0}[Errore] {1}",
			"sparkJobSubmission.LivyNoLogReturned": "Nella risposta non è stato restituito alcun log.{0}[Errore] {1}"
		},
		"dist/sqlClusterLookUp": {
			"bdcConnectError": "Errore: {0}. ",
			"promptBDCPassword": "Specificare la password per la connessione al controller BDC",
			"promptBDCUsername": "{0}Specificare il nome utente per la connessione al controller BDC:",
			"usernameAndPasswordRequired": "Il nome utente e la password sono obbligatori"
		},
		"dist/sqlToolsServer": {
			"downloadServiceDoneChannelMsg": "Installazione di {0} completata",
			"downloadingServiceChannelMsg": "Download di {0}",
			"downloadingServiceSizeChannelMsg": "({0} KB)",
			"downloadingServiceStatusMsg": "Download di {0}",
			"entryExtractedChannelMsg": "Estratto {0} ({1}/{2})",
			"failedToStartServiceErrorMsg": "Non è stato possibile avviare {0}",
			"installedServiceChannelMsg": "{0} installato",
			"installingServiceChannelMsg": "Installazione di {0} in {1}",
			"installingServiceStatusMsg": "Installazione di {0}",
			"serviceStartedStatusMsg": "{0} avviato",
			"startingServiceStatusMsg": "Avvio di {0}"
		},
		"dist/telemetry": {
			"serviceCrashMessage": "Il componente {0} è stato chiuso in modo imprevisto. Riavviare Azure Data Studio.",
			"viewKnownIssuesText": "Visualizza problemi noti"
		},
		"package": {
			"cloud.databaseProperties.azureEdition": "Edizione",
			"cloud.databaseProperties.compatibilityLevel": "Livello di compatibilità",
			"cloud.databaseProperties.owner": "Proprietario",
			"cloud.databaseProperties.serviceLevelObjective": "Piano tariffario",
			"cloud.serverProperties.serverEdition": "Tipo",
			"cloud.serverProperties.serverVersion": "Versione",
			"databasesListProperties.lastBackup": "Ultimo backup",
			"databasesListProperties.name": "Nome",
			"databasesListProperties.size": "Dimensioni (MB)",
			"databasesListProperties.status": "Stato",
			"json.format.enable.desc": "Abilita/Disabilita il formattatore JSON predefinito (richiede il riavvio)",
			"json.schemas.desc": "Associa schemi a file JSON nel progetto corrente",
			"json.schemas.fileMatch.desc": "Matrice di criteri dei file da usare per la ricerca durante la risoluzione di file JSON in schemi.",
			"json.schemas.fileMatch.item.desc": "Criteri dei file che possono contenere '*' da usare per la ricerca durante la risoluzione di file JSON in schemi.",
			"json.schemas.schema.desc": "Definizione dello schema per l'URL specificato. È necessario specificare lo schema per evitare accessi all'URL dello schema.",
			"json.schemas.url.desc": "URL di uno schema o percorso relativo di uno schema nella directory corrente",
			"mssql.configuration.title": "Configurazione di MSSQL",
			"mssql.connectionOptions.applicationIntent.description": "Dichiara il tipo di carico di lavoro dell'applicazione durante la connessione a un server",
			"mssql.connectionOptions.applicationIntent.displayName": "Finalità dell'applicazione",
			"mssql.connectionOptions.applicationName.description": "Nome dell'applicazione",
			"mssql.connectionOptions.applicationName.displayName": "Nome dell'applicazione",
			"mssql.connectionOptions.asynchronousProcessing.description": "Se è true, consente l'utilizzo della funzionalità asincrona nel provider di dati .NET Framework.",
			"mssql.connectionOptions.asynchronousProcessing.displayName": "Elaborazione asincrona",
			"mssql.connectionOptions.attachDbFilename.displayName": "Collega nome file del database",
			"mssql.connectionOptions.attachedDBFileName.description": "Nome del file primario, incluso il nome del percorso completo, di un database collegabile",
			"mssql.connectionOptions.attachedDBFileName.displayName": "Nome file del database collegato",
			"mssql.connectionOptions.authType.categoryValues.azureMFA": "Azure Active Directory - Universale con supporto MFA",
			"mssql.connectionOptions.authType.categoryValues.integrated": "Autenticazione di Windows",
			"mssql.connectionOptions.authType.categoryValues.sqlLogin": "Account di accesso SQL",
			"mssql.connectionOptions.authType.description": "Specifica il metodo di autenticazione con SQL Server",
			"mssql.connectionOptions.authType.displayName": "Tipo di autenticazione",
			"mssql.connectionOptions.columnEncryptionSetting.description": "Abilita o disabilita Always Encrypted per la connessione",
			"mssql.connectionOptions.columnEncryptionSetting.displayName": "Always Encrypted",
			"mssql.connectionOptions.connectRetryCount.description": "Numero di tentativi di ripristino della connessione",
			"mssql.connectionOptions.connectRetryCount.displayName": "Conteggio tentativi di connessione",
			"mssql.connectionOptions.connectRetryInterval.description": "Ritardo tra tentativi di ripristino della connessione",
			"mssql.connectionOptions.connectRetryInterval.displayName": "Intervallo tentativi di connessione",
			"mssql.connectionOptions.connectTimeout.description": "Intervallo di tempo (in secondi) in cui attendere la connessione al server prima di interrompere il tentativo e generare un errore",
			"mssql.connectionOptions.connectTimeout.displayName": "Timeout di connessione",
			"mssql.connectionOptions.connectionName.description": "Nome personalizzato della connessione",
			"mssql.connectionOptions.connectionName.displayName": "Nome (facoltativo)",
			"mssql.connectionOptions.contextConnection.description": "Se è true, indica che la connessione deve provenire dal contesto SQL Server. Disponibile solo quando è in esecuzione nel processo SQL Server",
			"mssql.connectionOptions.contextConnection.displayName": "Connessione al contesto",
			"mssql.connectionOptions.currentLanguage.description": "Nome del record di lingua di SQL Server",
			"mssql.connectionOptions.currentLanguage.displayName": "Lingua corrente",
			"mssql.connectionOptions.databaseName.description": "Nome del database o del catalogo iniziale nell'origine dati",
			"mssql.connectionOptions.databaseName.displayName": "Database",
			"mssql.connectionOptions.enclaveAttestationProtocol.categoryValues.AAS": "Attestazione di Azure",
			"mssql.connectionOptions.enclaveAttestationProtocol.categoryValues.HGS": "Servizio Sorveglianza host",
			"mssql.connectionOptions.enclaveAttestationProtocol.description": "Specifica un protocollo per l'attestazione di un enclave lato server usato con Always Encrypted con enclave sicuri",
			"mssql.connectionOptions.enclaveAttestationProtocol.displayName": "Protocollo di attestazione",
			"mssql.connectionOptions.enclaveAttestationUrl.description": "Specifica un endpoint per l'attestazione di un enclave lato server usato con Always Encrypted con enclavi sicuri",
			"mssql.connectionOptions.enclaveAttestationUrl.displayName": "URL di attestazione enclave",
			"mssql.connectionOptions.encrypt.description": "Se è true, SQL Server usa la crittografia SSL per tutti i dati scambiati tra il client e il server, se nel server è installato un certificato",
			"mssql.connectionOptions.encrypt.displayName": "Crittografa",
			"mssql.connectionOptions.failoverPartner.description": "Nome o indirizzo di rete dell'istanza di SQL Server che funge da partner di failover",
			"mssql.connectionOptions.failoverPartner.displayName": "Partner di failover",
			"mssql.connectionOptions.groupName.advanced": "Avanzata",
			"mssql.connectionOptions.groupName.connectionResiliency": "Resilienza connessione",
			"mssql.connectionOptions.groupName.context": "Contesto",
			"mssql.connectionOptions.groupName.initialization": "Inizializzazione",
			"mssql.connectionOptions.groupName.pooling": "Pooling",
			"mssql.connectionOptions.groupName.replication": "Replica",
			"mssql.connectionOptions.groupName.security": "Sicurezza",
			"mssql.connectionOptions.groupName.source": "Origine",
			"mssql.connectionOptions.loadBalanceTimeout.description": "Tempo minimo (in secondi) in cui la connessione rimane attiva nel pool prima di essere eliminata definitivamente",
			"mssql.connectionOptions.loadBalanceTimeout.displayName": "Timeout durante il bilanciamento del carico",
			"mssql.connectionOptions.maxPoolSize.description": "Numero massimo di connessioni consentite nel pool",
			"mssql.connectionOptions.maxPoolSize.displayName": "Dimensioni massime del pool",
			"mssql.connectionOptions.minPoolSize.description": "Numero minimo di connessioni consentite nel pool",
			"mssql.connectionOptions.minPoolSize.displayName": "Dimensioni minime del pool",
			"mssql.connectionOptions.multiSubnetFailover.displayName": "Failover su più subnet",
			"mssql.connectionOptions.multipleActiveResultSets.description": "Se è true, possono essere restituiti e letti più set di risultati da un'unica connessione",
			"mssql.connectionOptions.multipleActiveResultSets.displayName": "Multiple Active Result Set",
			"mssql.connectionOptions.packetSize.description": "Dimensioni in byte dei pacchetti di rete usati per comunicare con un'istanza di SQL Server",
			"mssql.connectionOptions.packetSize.displayName": "Dimensioni del pacchetto",
			"mssql.connectionOptions.password.description": "Indica la password da usare per la connessione all'origine dati",
			"mssql.connectionOptions.password.displayName": "Password",
			"mssql.connectionOptions.persistSecurityInfo.description": "Se è false, le informazioni sensibili dal punto di vista della sicurezza, come la password, non vengono restituite nell'ambito della connessione",
			"mssql.connectionOptions.persistSecurityInfo.displayName": "Salva in modo permanente le informazioni di sicurezza",
			"mssql.connectionOptions.pooling.description": "Se è true, l'oggetto connessione viene prelevato dal pool appropriato oppure, se necessario, viene creato e aggiunto al pool appropriato",
			"mssql.connectionOptions.pooling.displayName": "Pooling",
			"mssql.connectionOptions.port.displayName": "Porta",
			"mssql.connectionOptions.replication.description": "Usato da SQL Server nella replica",
			"mssql.connectionOptions.replication.displayName": "Replica",
			"mssql.connectionOptions.serverName.description": "Nome dell'istanza di SQL Server",
			"mssql.connectionOptions.serverName.displayName": "Server",
			"mssql.connectionOptions.trustServerCertificate.description": "Se è true (ed encrypt=true), SQL Server usa la crittografia SSL per tutti i dati inviati tra il client e il server senza convalidare il certificato del server",
			"mssql.connectionOptions.trustServerCertificate.displayName": "Considera attendibile il certificato del server",
			"mssql.connectionOptions.typeSystemVersion.description": "Indica quale sistema di tipi di server il provider esporrà mediante il DataReader",
			"mssql.connectionOptions.typeSystemVersion.displayName": "Versione del sistema di tipi",
			"mssql.connectionOptions.userName.description": "Indica l'ID utente da usare per la connessione all'origine dati",
			"mssql.connectionOptions.userName.displayName": "Nome utente",
			"mssql.connectionOptions.workstationId.description": "Nome della workstation che si connette a SQL Server",
			"mssql.connectionOptions.workstationId.displayName": "ID workstation",
			"mssql.disabled": "Disabilitato",
			"mssql.enabled": "Abilitato",
			"mssql.exportNotebookToSql": "Esporta notebook come SQL",
			"mssql.exportSqlAsNotebook": "Esporta SQL come notebook",
			"mssql.format.alignColumnDefinitionsInColumns": "Consente di indicare se le definizioni di colonna devono essere allineate",
			"mssql.format.datatypeCasing": "Consente di indicare se ai tipi di dati deve essere applicata la formattazione in lettere MAIUSCOLE o minuscole oppure se non deve essere applicata alcuna formattazione",
			"mssql.format.keywordCasing": "Consente di indicare se alle parole chiave deve essere applicata la formattazione in lettere MAIUSCOLE o minuscole oppure se non deve essere applicata alcuna formattazione",
			"mssql.format.placeCommasBeforeNextStatement": "Consente di indicare se le virgole devono essere inserite all'inizio di ogni istruzione in un elenco, ad esempio ', mycolumn2', anziché alla fine, ad esempio 'mycolumn1,'?",
			"mssql.format.placeSelectStatementReferencesOnNewLine": "Consente di indicare se i riferimenti agli oggetti in istruzioni select devono essere suddivisi su righe diverse. Ad esempio per 'SELECT C1, C2 FROM T1' sia C1 che C2 saranno su righe diverse",
			"mssql.ignorePlatformWarning": "[Facoltativa] Non visualizzare avvisi su piattaforme non supportate",
			"mssql.intelliSense.enableErrorChecking": "Consente di indicare se il controllo degli errori di IntelliSense deve essere abilitato",
			"mssql.intelliSense.enableIntelliSense": "Consente di indicare se IntelliSense deve essere abilitato",
			"mssql.intelliSense.enableQuickInfo": "Consente di indicare se le informazioni rapide di IntelliSense devono essere abilitate",
			"mssql.intelliSense.enableSuggestions": "Consente di indicare se i suggerimenti IntelliSense devono essere abilitati",
			"mssql.intelliSense.lowerCaseSuggestions": "Consente di indicare se applicare la formattazione in lettere minuscole ai suggerimenti di IntelliSense",
			"mssql.logDebugInfo": "[Facoltativa] Registrare l'output di debug nella console (Visualizza -> Output), quindi selezionare il canale di output appropriato dall'elenco a discesa",
			"mssql.logFilesRemovalLimit": "Numero massimo di file meno recenti da rimuovere all'avvio per cui è scaduto il tempo impostato con mssql.logRetentionMinutes. I file che non vengono rimossi a causa di questa limitazione verranno rimossi al successivo avvio di Azure Data Studio.",
			"mssql.logRetentionMinutes": "Numero di minuti per la conservazione dei file di log per i servizi di back-end. L'impostazione predefinita è 1 settimana.",
			"mssql.provider.displayName": "Microsoft SQL Server",
			"mssql.query.alwaysEncryptedParameterization": "Abilita parametrizzazione per Always Encrypted",
			"mssql.query.ansiDefaults": "Abilita SET ANSI_DEFAULTS",
			"mssql.query.ansiNullDefaultOn": "Abilita SET ANSI_NULL_DFLT_ON",
			"mssql.query.ansiNulls": "Abilita SET ANSI_NULLS",
			"mssql.query.ansiPadding": "Abilita SET ANSI_PADDING",
			"mssql.query.ansiWarnings": "Abilita SET ANSI_WARNINGS",
			"mssql.query.arithAbort": "Abilita l'opzione SET ARITHABORT",
			"mssql.query.cursorCloseOnCommit": "Abilita SET CURSOR_CLOSE_ON_COMMIT",
			"mssql.query.deadlockPriority": "Abilita l'opzione SET DEADLOCK_PRIORITY",
			"mssql.query.displayBitAsNumber": "Consente di indicare se le colonne di tipo BIT devono essere visualizzate come numeri (1 o 0). Se è 'false', verranno visualizzate come 'true' o 'false'",
			"mssql.query.executionTimeout": "L'impostazione del valore 0 per il timeout di esecuzione indica un'attesa illimitata (nessun timeout)",
			"mssql.query.implicitTransactions": "Abilita SET IMPLICIT_TRANSACTIONS",
			"mssql.query.lockTimeout": "Abilita l'opzione SET LOCK TIMEOUT (in millisecondi)",
			"mssql.query.maxXmlCharsToStore": "Numero di caratteri XML da archiviare dopo l'esecuzione di una query",
			"mssql.query.noCount": "Abilita l'opzione SET NOCOUNT",
			"mssql.query.noExec": "Abilita l'opzione SET NOEXEC",
			"mssql.query.parseOnly": "Abilita l'opzione SET PARSEONLY",
			"mssql.query.queryGovernorCostLimit": "Abilita SET QUERY_GOVERNOR_COST_LIMIT",
			"mssql.query.quotedIdentifier": "Abilita SET QUOTED_IDENTIFIER",
			"mssql.query.setRowCount": "Numero massimo di righe da restituire prima che il server arresti l'elaborazione della query.",
			"mssql.query.statisticsIO": "Abilita L'opzione SET STATISTICS IO",
			"mssql.query.statisticsTime": "Abilita l'opzione SET STATISTICS TIME",
			"mssql.query.textSize": "Dimensioni massime dei dati di tipo text e ntext restituiti da un'istruzione SELECT",
			"mssql.query.transactionIsolationLevel": "Abilita l'opzione SET TRANSACTION ISOLATION LEVEL",
			"mssql.query.xactAbortOn": "Abilita l'opzione SET XACT_ABORT ON",
			"mssql.tracingLevel": "[Facoltativa] Livello di registrazione per i servizi back-end. Azure Data Studio genera un nome file a ogni avvio e, se il file esiste già, le voci del log vengono accodate a tale file. Per la pulizia dei file di log meno recenti, vedere le impostazioni logRetentionMinutes e logFilesRemovalLimit. Con l'impostazione predefinita di tracingLevel, la quantità di dati registrata non è eccessiva. Se si cambia il livello di dettaglio, la registrazione potrebbe diventare eccessiva e richiedere un notevole spazio su disco per i log. Il livello Error include quello Critical, il livello Warning include quello Error, il livello Information include quello Warning e il livello Verbose include quello Information",
			"mssqlCluster.copyPath": "Copia percorso",
			"mssqlCluster.deleteFiles": "Elimina",
			"mssqlCluster.manageAccess": "Gestisci accesso",
			"mssqlCluster.mkdir": "Nuova directory",
			"mssqlCluster.previewFile": "Anteprima",
			"mssqlCluster.saveFile": "Salva",
			"mssqlCluster.uploadFiles": "Carica file",
			"notebook.command.new": "Nuovo notebook",
			"notebook.command.open": "Apri notebook",
			"objectsListProperties.name": "Nome",
			"onprem.databaseProperties.compatibilityLevel": "Livello di compatibilità",
			"onprem.databaseProperties.lastBackupDate": "Ultimo backup del database",
			"onprem.databaseProperties.lastLogBackupDate": "Ultimo backup del log",
			"onprem.databaseProperties.owner": "Proprietario",
			"onprem.databaseProperties.recoveryModel": "Modello di recupero",
			"onprem.serverProperties.machineName": "Nome del computer",
			"onprem.serverProperties.osVersion": "Versione del sistema operativo",
			"onprem.serverProperties.serverEdition": "Edizione",
			"onprem.serverProperties.serverVersion": "Versione",
			"tab.bigDataClusterDescription": "Attività e informazioni sul cluster Big Data di SQL Server",
			"title.bigDataCluster": "Cluster Big Data di SQL Server",
			"title.books": "Notebooks",
			"title.clearSearchServerResult": "Ricerca: Cancella risultati del server di ricerca",
			"title.configurePython": "Configura Python per Notebooks",
			"title.designTable": "Progettazione",
			"title.endpoints": "Endpoint servizio",
			"title.installPackages": "Installa pacchetti",
			"title.newSparkJob": "Nuovo processo Spark",
			"title.newTable": "Nuova tabella",
			"title.openClusterDashboard": "Dashboard\r\ncluster",
			"title.openSparkHistory": "Visualizza cronologia di Spark",
			"title.openYarnHistory": "Visualizza cronologia di YARN",
			"title.searchServers": "Ricerca: Server",
			"title.showLogFile": "Mostra file di log",
			"title.submitSparkJob": "Invia processo Spark",
			"title.tasks": "Attività"
		}
	}
}