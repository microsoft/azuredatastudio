{
	"": [
		"--------------------------------------------------------------------------------------------",
		"Copyright (c) Microsoft Corporation. All rights reserved.",
		"Licensed under the Source EULA. See License.txt in the project root for license information.",
		"--------------------------------------------------------------------------------------------",
		"Do not edit this file. It is machine generated."
	],
	"version": "1.0.0",
	"contents": {
		"dist/dashboard/serviceEndpoints": {
			"copyText": "複製",
			"endpoint.appproxy": "應用程式 Proxy",
			"endpoint.controller": "叢集管理服務",
			"endpoint.gateway": "用來存取 HDFS 檔案的閘道，Spark",
			"endpoint.grafana": "計量儀表板",
			"endpoint.kibana": "記錄搜尋儀表板",
			"endpoint.livy": "用來執行 Spark 陳述式、作業、應用程式的 Proxy",
			"endpoint.managementproxy": "管理 Proxy",
			"endpoint.mgmtproxy": "管理 Proxy",
			"endpoint.sparkHistory": "Spark 作業管理與監視儀表板",
			"endpoint.sqlServerEndpoint": "SQL Server 主要執行個體前端",
			"endpoint.webhdfs": "HDFS 檔案系統 Proxy",
			"endpoint.yarnHistory": "Spark 診斷與監視儀表板",
			"grafana": "計量儀表板",
			"kibana": "記錄搜尋儀表板",
			"sparkHistory": "Spark 作業管理與監視儀表板",
			"yarnHistory": "Spark 診斷與監視儀表板"
		},
		"dist/features": {
			"mssql.canceledLinkedAzureAccountSelection": "Azure Data Studio 必須連絡 Azure Key Vault 以存取 Always Encrypted 的資料行主要金鑰，但沒有選取任何已連結的 Azure 帳戶。請重試一次此查詢，並在提示出現時選取已連結的 Azure 帳戶。",
			"mssql.chooseLinkedAzureAccount": "請選取已連結的 Azure 帳戶:",
			"mssql.insufficientlyPrivelagedAzureAccount": "為 {0} 所設定的 Azure 帳戶，沒有足夠的權限讓 Azure Key Vault 存取 Always Encrypted 的資料行主要金鑰。",
			"mssql.missingLinkedAzureAccount": "Azure Data Studio 必須連絡 Azure Key Vault 以存取 Always Encrypted 的資料行主要金鑰，但沒有任何已連結的 Azure 帳戶可供使用。請新增已連結的 Azure 帳戶，然後重試一次此查詢。"
		},
		"dist/hdfs/hdfsModel": {
			"mssql.recursivePermissionOpError": "套用權限變更時發生錯誤: {0}",
			"mssql.recursivePermissionOpProgress": "將權限變更套用到 ‘{0}’",
			"mssql.recursivePermissionOpStarted": "正在 ‘{0}’ 下遞迴套用權限變更",
			"mssql.recursivePermissionOpSucceeded": "已成功套用權限變更。"
		},
		"dist/hdfs/webhdfs": {
			"webhdfs.httpError400": "不正確的要求",
			"webhdfs.httpError401": "未經授權",
			"webhdfs.httpError403": "禁止",
			"webhdfs.httpError404": "找不到",
			"webhdfs.httpError500": "內部伺服器錯誤",
			"webhdfs.invalidDataStructure": "資料結構無效",
			"webhdfs.missingProperties": "因為缺少選項，所以無法建立 WebHDFS 用戶端: ${0}",
			"webhdfs.undefinedArgument": "'${0}' 未定義。",
			"webhdfs.unexpectedRedirect": "未預期的重新導向",
			"webhdfs.unknownError": "未知的錯誤"
		},
		"dist/localizedConstants": {
			"msgMissingNodeContext": "已呼叫節點命令，但未傳遞任何節點",
			"mssql.accessHeader": "存取",
			"mssql.addLabel": "新增",
			"mssql.addUserOrGroup": "新增使用者或群組",
			"mssql.apply": "套用",
			"mssql.applyRecursively": "遞迴套用",
			"mssql.defaultHeader": "預設",
			"mssql.defaultUserAndGroups": "預設使用者與群組",
			"mssql.delete": "刪除",
			"mssql.enterNamePlaceholder": "輸入名稱",
			"mssql.errorApplyingAclChanges": "套用變更時發生未預期的錯誤: {0}",
			"mssql.everyone": "其他人",
			"mssql.executeHeader": "執行",
			"mssql.group": "群組",
			"mssql.groupLabel": "群組",
			"mssql.inheritDefaultsLabel": "繼承預設值",
			"mssql.locationTitle": "位置:",
			"mssql.manageAccessTitle": "管理存取權",
			"mssql.namedUsersAndGroups": "具名使用者和群組",
			"mssql.owner": "擁有者",
			"mssql.ownerPostfix": "- 擁有者",
			"mssql.owningGroupPostfix": "- 擁有群組",
			"mssql.permissionsTitle": "權限",
			"mssql.readHeader": "讀取",
			"mssql.stickyHeader": "固著位元",
			"mssql.userLabel": "使用者",
			"mssql.userOrGroupIcon": "使用者或群組圖示",
			"mssql.writeHeader": "寫入",
			"sparkConnectionRequired": "請先連線至 Spark 叢集，再檢視 {0} 歷程記錄。",
			"sparkJobSubmission.GetApplicationIdFailed": "無法取得應用程式識別碼。{0}",
			"sparkJobSubmission.LocalFileDestinationHint": "本機檔案將上傳至 HDFS。",
			"sparkJobSubmission.LocalFileNotExisted": "本機檔案 {0} 不存在。",
			"sparkJobSubmission.NoSqlBigDataClusterFound": "找不到任何 SQL Server 巨量資料叢集。",
			"sparkJobSubmission.PrepareSubmitJob": "正在提交作業 {0}... ",
			"sparkJobSubmission.PrepareUploadingFile": "正在從本機 {0} 將檔案上傳至 HDFS 資料夾: {1}",
			"sparkJobSubmission.SparkHistoryLinkMessage": "Spark 歷程記錄 Url: {0}",
			"sparkJobSubmission.SubmissionEndMessage": ".......................... 提交 Spark 作業結束 ............................",
			"sparkJobSubmission.SubmitJobFailed": "Spark 作業提交失敗。{0}",
			"sparkJobSubmission.SubmitJobFinished": "已提交 Spark 作業。",
			"sparkJobSubmission.UploadingFileFailed": "無法將檔案上傳至叢集。{0}",
			"sparkJobSubmission.UploadingFileSucceeded": "已成功將檔案上傳至叢集!",
			"sparkJobSubmission.YarnUIMessage": "YarnUI Url: {0} "
		},
		"dist/main": {
			"msgSampleCodeDataFrame": "這個範例程式碼會將檔案載入資料框架，並顯示前 10 個結果。",
			"mssql.errorConvertingToNotebook": "將 SQL 文件轉換成筆記本時發生錯誤。錯誤: {0}",
			"mssql.errorConvertingToSQL": "將筆記本文件轉換成 SQL 時發生錯誤。錯誤: {0}",
			"noController": "找不到此執行個體的控制器端點",
			"notebookFileType": "Notebooks",
			"unsupportedFileType": "僅支援 .ipynb Notebooks"
		},
		"dist/objectExplorerNodeProvider/cancelableStream": {
			"streamCanceled": "使用者取消了串流作業"
		},
		"dist/objectExplorerNodeProvider/command": {
			"cancel": "要取消作業嗎?",
			"cancelTooltip": "取消",
			"mssql.searchServers": "搜尋伺服器名稱",
			"progress": "$(sync~spin) {0}..."
		},
		"dist/objectExplorerNodeProvider/connection": {
			"connectionInfoOptionsMissingProperties": "connectionInfo.options 中遺失的部分屬性: {0}",
			"connectionInfoOptionsUndefined": "未定義 ConnectionInfo.options。",
			"connectionInfoUndefined": "未定義 ConnectionInfo。"
		},
		"dist/objectExplorerNodeProvider/fileSources": {
			"maxSizeNotice": "注意: 此檔案已於 {0} 截斷，以供預覽。",
			"maxSizeReached": "檔案已於 {0} 截斷，以供預覽。"
		},
		"dist/objectExplorerNodeProvider/hdfsCommands": {
			"allFiles": "所有檔案",
			"copyPathError": "複製路徑時發生錯誤: {0}",
			"deleteError": "刪除檔案時發生錯誤: {0}",
			"enterDirName": "輸入目錄名稱",
			"lblUploadFiles": "上傳",
			"makingDir": "正在建立目錄",
			"manageAccessError": "開啟管理存取權對話方塊時發生未預期的錯誤: {0}",
			"mkDirError": "製作目錄時發生錯誤: {0}",
			"mkdirCanceled": "作業已取消",
			"msgDeleteFile": "確定要刪除此檔案嗎?",
			"msgDeleteFolder": "確定要刪除此資料夾和其內容嗎?",
			"previewError": "預覽檔案時發生錯誤: {0}",
			"previewing": "正在產生預覽",
			"saveCanceled": "儲存作業已取消",
			"saveError": "儲存檔案時發生錯誤: {0}",
			"saving": "正在儲存 HDFS 檔案",
			"uploadCanceled": "上傳作業已取消",
			"uploadError": "上傳檔案時發生錯誤: {0}",
			"uploading": "正在將檔案上傳至 HDFS"
		},
		"dist/objectExplorerNodeProvider/hdfsProvider": {
			"errDeleteConnectionNode": "無法刪除連線。只能刪除子資料夾和檔案。",
			"errorExpanding": "錯誤: {0}"
		},
		"dist/objectExplorerNodeProvider/objectExplorerNodeProvider": {
			"hdfsFolder": "HDFS",
			"notifyError": "通知節點變更時發生錯誤: {0}",
			"prmptPwd": "請提供連線至 HDFS 的密碼:",
			"promptUsername": "請提供連線至 HDFS 的使用者名稱:",
			"rootLabel": "根",
			"sessionNotFound": "節點 {0} 的工作階段不存在"
		},
		"dist/prompts/confirm": {
			"msgNo": "否",
			"msgYes": "是"
		},
		"dist/sparkFeature/dialog/dialogCommands": {
			"errorNotSqlBigDataCluster": "所選伺服器不屬於 SQL Server 巨量資料叢集",
			"selectOtherServer": "選取其他 SQL Server",
			"sparkJobSubmission.GetFilePathFromSelectedNodeFailed": "取得檔案路徑時發生錯誤: {0}",
			"sparkJobSubmission.NoSqlSelected": "未選取任何 SQL Server。",
			"sparkJobSubmission.PleaseSelectSqlWithCluster": "請選取具有巨量資料叢集的 SQL Server。"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkAdvancedTab": {
			"sparkJobSubmission.AdvancedTabName": "進階",
			"sparkJobSubmission.ReferenceFilesList": "參考檔案",
			"sparkJobSubmission.ReferenceFilesListTooltip": "要放置於執行程式工作目錄的檔案。檔案路徑必須為 HDFS 路徑。多個路徑應以分號 (;) 分隔",
			"sparkJobSubmission.ReferenceJarList": "參考 JAR",
			"sparkJobSubmission.ReferenceJarListToolTip": "要放置在執行程式工作目錄中的 Jar。Jar 路徑必須為 HDFS 路徑。多個路徑應以分號 (;) 分隔",
			"sparkJobSubmission.ReferencePyList": "參考 py 檔案",
			"sparkJobSubmission.ReferencePyListTooltip": "要放置於執行程式工作目錄的 Py 檔案。檔案路徑必須為 HDFS 路徑。多個路徑應以分號 (;) 分隔",
			"sparkJobSubmission.configValues": "組態值",
			"sparkJobSubmission.configValuesTooltip": "包含 Spark 組態值的成對名稱值清單。編碼為 JSON 字典。範例: '{\"name\":\"value\", \"name2\":\"value2\"}'。",
			"sparkJobSubmission.driverCores": "驅動程式核心",
			"sparkJobSubmission.driverCoresTooltip": "要配置給驅動程式的 CPU 核心數量。",
			"sparkJobSubmission.driverMemory": "驅動程式記憶體",
			"sparkJobSubmission.driverMemoryTooltip": "要配置給驅動程式的記憶體數量。指定單位作為值的一部分。範例: 512M 或 2G。",
			"sparkJobSubmission.executorCores": "執行程式核心",
			"sparkJobSubmission.executorCoresTooltip": "要配置給執行程式的 CPU 核心數量。",
			"sparkJobSubmission.executorCount": "執行程式計數",
			"sparkJobSubmission.executorCountTooltip": "要執行執行程式的執行個體數目。",
			"sparkJobSubmission.executorMemory": "執行程式記憶體",
			"sparkJobSubmission.executorMemoryTooltip": "要配置給執行程式的記憶體數量。指定單位作為值的一部分。範例: 512M 或 2G。",
			"sparkJobSubmission.queueName": "佇列名稱",
			"sparkJobSubmission.queueNameTooltip": "要在其中執行工作階段的 Spark 佇列名稱。"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkConfigurationTab": {
			"sparkJobSubmission.Arguments": "引數",
			"sparkJobSubmission.ArgumentsTooltip": "在您主要類別中使用的命令列引數，多個引數應以空格分隔。",
			"sparkJobSubmission.FilePathPlaceHolder": ".jar 或 .py 檔案的路徑",
			"sparkJobSubmission.GeneralTabName": "一般",
			"sparkJobSubmission.HDFSFileNotExisted": "指定的 HDFS 檔案不存在。",
			"sparkJobSubmission.HDFSFileNotExistedWithPath": "{0} 不存在於叢集或擲回例外狀況中。",
			"sparkJobSubmission.JobName": "作業名稱",
			"sparkJobSubmission.JobNamePlaceHolder": "輸入名稱...",
			"sparkJobSubmission.LocalFileDestinationHintWithPath": "選取的本機檔案將會上傳至 HDFS: {0}",
			"sparkJobSubmission.MainClass": "主要類別",
			"sparkJobSubmission.MainFilePath": "JAR/py 檔案",
			"sparkJobSubmission.NotSpecifyJARPYPath": "未指定屬性 JAR/py 檔案。",
			"sparkJobSubmission.NotSpecifyJobName": "未指定屬性作業名稱。",
			"sparkJobSubmission.NotSpecifyMainClass": "未指定屬性主要類別。",
			"sparkJobSubmission.SelectFileError": "因為發生錯誤，所以在尋找檔案時發生錯誤: {0}",
			"sparkJobSubmission.SparkCluster": "Spark 叢集",
			"sparkSelectLocalFile": "選擇"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionDialog": {
			"sparkJobSubmission.DialogCancelButton": "取消",
			"sparkJobSubmission.DialogSubmitButton": "提交",
			"sparkJobSubmission.DialogTitleNewJob": "新增作業",
			"sparkJobSubmission.SparkJobSubmissionDialogInitializeError": "SparkJobSubmissionDialog 的參數不合法",
			"sparkJobSubmission.SubmissionStartMessage": ".......................... 提交 Spark 作業開始 ..........................",
			"sparkJobSubmission.SubmitSparkJob": "{0} Spark 作業提交:"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionModel": {
			"sparkJobSubmission.GetApplicationIdTimeOut": "取得應用程式識別碼逾時。{0}[記錄]   {1}",
			"sparkJobSubmission.LivyBatchIdIsInvalid": "livyBatchId 無效。 ",
			"sparkJobSubmission.PathNotSpecified.": "未指定屬性路徑。",
			"sparkJobSubmission.SparkJobSubmissionModelInitializeError": "SparkJobSubmissionModel 的參數不合法",
			"sparkJobSubmission.localFileOrFolderNotSpecified.": "未指定屬性 localFilePath 或 hdfsFolderPath。",
			"sparkJobSubmission.submissionArgsIsInvalid": "submissionArgs 無效。 "
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionService": {
			"sparkJobSubmission.LivyNoBatchIdReturned": "回應未傳回任何 Spark 作業批次識別碼。{0}[錯誤] {1}",
			"sparkJobSubmission.LivyNoLogReturned": "回應中未傳回任何記錄。{0}[錯誤] {1}"
		},
		"dist/sqlClusterLookUp": {
			"bdcConnectError": "錯誤: {0}。 ",
			"promptBDCPassword": "請提供密碼以連線至 BDC 控制器",
			"promptBDCUsername": "{0}請提供使用者名稱以連線至 BDC 控制器:",
			"usernameAndPasswordRequired": "需要使用者名稱與密碼"
		},
		"dist/sqlToolsServer": {
			"downloadServiceDoneChannelMsg": "已完成 {0} 的安裝",
			"downloadingServiceChannelMsg": "正在下載 {0}",
			"downloadingServiceSizeChannelMsg": "({0} KB)",
			"downloadingServiceStatusMsg": "正在下載 {0}",
			"entryExtractedChannelMsg": "已擷取 {0} ({1}/{2})",
			"failedToStartServiceErrorMsg": "無法啟動 {0}",
			"installedServiceChannelMsg": "已安裝 {0}",
			"installingServiceChannelMsg": "正在將 {0} 安裝到 {1}",
			"installingServiceStatusMsg": "正在安裝 {0}",
			"serviceStartedStatusMsg": "已啟動 {0}",
			"startingServiceStatusMsg": "正在啟動 {0}"
		},
		"dist/telemetry": {
			"serviceCrashMessage": "{0} 個元件意外結束。請重新啟動 Azure Data Studio。",
			"viewKnownIssuesText": "檢視已知問題"
		},
		"package": {
			"cloud.databaseProperties.azureEdition": "版本",
			"cloud.databaseProperties.compatibilityLevel": "相容性層級",
			"cloud.databaseProperties.owner": "擁有者",
			"cloud.databaseProperties.serviceLevelObjective": "定價層",
			"cloud.serverProperties.serverEdition": "類型",
			"cloud.serverProperties.serverVersion": "版本",
			"databasesListProperties.lastBackup": "上次備份",
			"databasesListProperties.name": "名稱",
			"databasesListProperties.size": "大小 (MB)",
			"databasesListProperties.status": "狀態",
			"json.format.enable.desc": "啟用/停用預設 JSON 格式器 (需要重新啟動)",
			"json.schemas.desc": "在結構描述與目前專案的 JSON 檔案之間建立關聯",
			"json.schemas.fileMatch.desc": "檔案模式陣列，在將 JSON 檔案解析成結構描述時的比對對象。",
			"json.schemas.fileMatch.item.desc": "可包含 '*' 的檔案模式，在將 JSON 檔案解析成結構描述時的比對對象。",
			"json.schemas.schema.desc": "指定 URL 的結構描述定義。只須提供結構描述以避免存取結構描述 URL。",
			"json.schemas.url.desc": "目前目錄中的結構描述 URL 或結構描述相對路徑",
			"mssql.configuration.title": "MSSQL 設定",
			"mssql.connectionOptions.applicationIntent.description": "在連線至伺服器時宣告應用程式工作負載類型",
			"mssql.connectionOptions.applicationIntent.displayName": "應用程式的意圖",
			"mssql.connectionOptions.applicationName.description": "應用程式的名稱",
			"mssql.connectionOptions.applicationName.displayName": "應用程式名稱",
			"mssql.connectionOptions.asynchronousProcessing.description": "若為 True，則允許使用 .Net Framework Data Provider 中的非同步功能",
			"mssql.connectionOptions.asynchronousProcessing.displayName": "非同步處理",
			"mssql.connectionOptions.attachDbFilename.displayName": "附加 DB 檔案名稱",
			"mssql.connectionOptions.attachedDBFileName.description": "主要檔案的名稱，包含可附加資料庫的完整路徑名稱",
			"mssql.connectionOptions.attachedDBFileName.displayName": "已附加的 DB 檔案名稱",
			"mssql.connectionOptions.authType.categoryValues.azureMFA": "Azure Active Directory - MFA 通用支援",
			"mssql.connectionOptions.authType.categoryValues.integrated": "Windows 驗證",
			"mssql.connectionOptions.authType.categoryValues.sqlLogin": "SQL 登入",
			"mssql.connectionOptions.authType.description": "指定向 SQL Server 驗證的方法",
			"mssql.connectionOptions.authType.displayName": "驗證類型",
			"mssql.connectionOptions.columnEncryptionSetting.description": "啟用或停用連線的 Always Encrypted 功能",
			"mssql.connectionOptions.columnEncryptionSetting.displayName": "Always Encrypted",
			"mssql.connectionOptions.connectRetryCount.description": "嘗試還原連線的次數",
			"mssql.connectionOptions.connectRetryCount.displayName": "連線重試計數",
			"mssql.connectionOptions.connectRetryInterval.description": "嘗試還原連線之間的延遲",
			"mssql.connectionOptions.connectRetryInterval.displayName": "連線重試間隔",
			"mssql.connectionOptions.connectTimeout.description": "終止嘗試並產生錯誤前，要等待伺服器連線的時間長度 (秒)",
			"mssql.connectionOptions.connectTimeout.displayName": "連線逾時",
			"mssql.connectionOptions.connectionName.description": "連線的自訂名稱",
			"mssql.connectionOptions.connectionName.displayName": "名稱 (選用)",
			"mssql.connectionOptions.contextConnection.description": "若為 True，則表示連線應來自 SQL 伺服器內容。僅可在於 SQL Server 處理序中執行時可用",
			"mssql.connectionOptions.contextConnection.displayName": "內容連線",
			"mssql.connectionOptions.currentLanguage.description": "SQL Server 語言記錄名稱",
			"mssql.connectionOptions.currentLanguage.displayName": "目前的語言",
			"mssql.connectionOptions.databaseName.description": "資料來源中，初始類別目錄或資料庫的名稱。",
			"mssql.connectionOptions.databaseName.displayName": "資料庫",
			"mssql.connectionOptions.enclaveAttestationProtocol.categoryValues.AAS": "Azure 證明",
			"mssql.connectionOptions.enclaveAttestationProtocol.categoryValues.HGS": "主機守護者服務",
			"mssql.connectionOptions.enclaveAttestationProtocol.description": "指定通訊協定，以證明與安全記憶體保護區一起使用 Always Encrypted 的伺服器端記憶體保護區",
			"mssql.connectionOptions.enclaveAttestationProtocol.displayName": "證明通訊協定",
			"mssql.connectionOptions.enclaveAttestationUrl.description": "指定端點，以證明與安全記憶體保護區一起使用 Always Encrypted 的伺服器端記憶體保護區",
			"mssql.connectionOptions.enclaveAttestationUrl.displayName": "記憶體保護區證明 URL",
			"mssql.connectionOptions.encrypt.description": "若為 True，則 SQL Server 會在伺服器已安裝憑證的情況下，對用戶端和伺服器間傳送的所有資料使用 SSL 加密",
			"mssql.connectionOptions.encrypt.displayName": "加密",
			"mssql.connectionOptions.failoverPartner.description": "充當容錯移轉夥伴之 SQL Server 執行個體的名稱或網路位址",
			"mssql.connectionOptions.failoverPartner.displayName": "容錯移轉夥伴",
			"mssql.connectionOptions.groupName.advanced": "進階",
			"mssql.connectionOptions.groupName.connectionResiliency": "恢復連接",
			"mssql.connectionOptions.groupName.context": "內容",
			"mssql.connectionOptions.groupName.initialization": "初始化",
			"mssql.connectionOptions.groupName.pooling": "共用",
			"mssql.connectionOptions.groupName.replication": "複寫",
			"mssql.connectionOptions.groupName.security": "安全性",
			"mssql.connectionOptions.groupName.source": "來源",
			"mssql.connectionOptions.loadBalanceTimeout.description": "此連線在終結前於集區中存留的時間下限 (秒)",
			"mssql.connectionOptions.loadBalanceTimeout.displayName": "負載平衡逾時",
			"mssql.connectionOptions.maxPoolSize.description": "集區中允許的連線數上限",
			"mssql.connectionOptions.maxPoolSize.displayName": "集區大小上限",
			"mssql.connectionOptions.minPoolSize.description": "集區中允許的連線數下限",
			"mssql.connectionOptions.minPoolSize.displayName": "集區大小下限",
			"mssql.connectionOptions.multiSubnetFailover.displayName": "多重子網路容錯移轉",
			"mssql.connectionOptions.multipleActiveResultSets.description": "若為 True，則可傳回多個結果集並從一個連線讀取",
			"mssql.connectionOptions.multipleActiveResultSets.displayName": "Multiple Active Result Set",
			"mssql.connectionOptions.packetSize.description": "用於和 SQL Server 執行個體通訊之網路封包的大小 (位元組)",
			"mssql.connectionOptions.packetSize.displayName": "封包大小",
			"mssql.connectionOptions.password.description": "代表要在連線至資料來源時使用的密碼",
			"mssql.connectionOptions.password.displayName": "密碼",
			"mssql.connectionOptions.persistSecurityInfo.description": "若為 False，則不會於連線中傳回密碼等安全性敏感資訊",
			"mssql.connectionOptions.persistSecurityInfo.displayName": "持續安全性資訊",
			"mssql.connectionOptions.pooling.description": "若為 True，則會從適當的集區提取連線物件，或在有需要時建立並新增至適當的集區",
			"mssql.connectionOptions.pooling.displayName": "共用",
			"mssql.connectionOptions.port.displayName": "連接埠",
			"mssql.connectionOptions.replication.description": "由 SQL Server 在複寫中使用",
			"mssql.connectionOptions.replication.displayName": "複寫",
			"mssql.connectionOptions.serverName.description": "SQL Server 執行個體的名稱",
			"mssql.connectionOptions.serverName.displayName": "伺服器",
			"mssql.connectionOptions.trustServerCertificate.description": "若為 True (且 encrypt=true)，則 SQL Server 會對用戶端和伺服器間傳送的所有資料使用 SSL 加密，而不驗證伺服器憑證",
			"mssql.connectionOptions.trustServerCertificate.displayName": "信任伺服器憑證",
			"mssql.connectionOptions.typeSystemVersion.description": "表示提供者透過 DataReader 所公開的伺服器類型系統",
			"mssql.connectionOptions.typeSystemVersion.displayName": "鍵入系統版本",
			"mssql.connectionOptions.userName.description": "代表要在連線至資料來源時使用的使用者識別碼",
			"mssql.connectionOptions.userName.displayName": "使用者名稱",
			"mssql.connectionOptions.workstationId.description": "連線至 SQL Server 的工作站名稱",
			"mssql.connectionOptions.workstationId.displayName": "工作站識別碼",
			"mssql.disabled": "已停用",
			"mssql.enabled": "已啟用",
			"mssql.exportNotebookToSql": "將筆記本匯出為 SQL",
			"mssql.exportSqlAsNotebook": "將 SQL 匯出為筆記本",
			"mssql.format.alignColumnDefinitionsInColumns": "行定義是否一致?",
			"mssql.format.datatypeCasing": "是否將資料類型轉換為大寫，小寫或無 (不轉換)",
			"mssql.format.keywordCasing": "是否將關鍵字轉換為大寫，小寫或無 (不轉換)",
			"mssql.format.placeCommasBeforeNextStatement": "逗號是否放在 list 中每個語句的開頭，例如: \", mycolumn2\" 而非在結尾，例如: \"mycolumn1,\"",
			"mssql.format.placeSelectStatementReferencesOnNewLine": "在 select 陳述式中參考的物件是否要分行處理? 以 'SELECT C1, C2 FROM T1' 為例，C1 與 C2 將會分行顯示",
			"mssql.ignorePlatformWarning": "[選用] 不要顯示不支援的平台警告",
			"mssql.intelliSense.enableErrorChecking": "是否啟用 IntelliSense 錯誤檢查",
			"mssql.intelliSense.enableIntelliSense": "是否啟用 IntelliSense",
			"mssql.intelliSense.enableQuickInfo": "是否啟用 IntelliSense 快速諮詢",
			"mssql.intelliSense.enableSuggestions": "是否啟用 IntelliSense 建議",
			"mssql.intelliSense.lowerCaseSuggestions": "是否將 IntelliSense 建議設定為小寫",
			"mssql.logDebugInfo": "[選用] 將偵錯記錄輸出至主控台 ([檢視] -> [輸出])，並從下拉式清單選取適當的輸出通道",
			"mssql.logFilesRemovalLimit": "具有到期的 logRetentionMinutes，且要於啟動時移除的舊檔案數上限。因為此限制而未清除的檔案，將於下次 Azure Data Studio 啟動時受到清除。",
			"mssql.logRetentionMinutes": "為後端服務保留記錄檔的分鐘數。預設為 1 週。",
			"mssql.provider.displayName": "Microsoft SQL Server",
			"mssql.query.alwaysEncryptedParameterization": "啟用 Always Encrypted 的參數化",
			"mssql.query.ansiDefaults": "啟用 SET ANSI_DEFAULTS",
			"mssql.query.ansiNullDefaultOn": "啟用 SET ANSI_NULL_DFLT_ON",
			"mssql.query.ansiNulls": "啟用 SET ANSI_NULLS",
			"mssql.query.ansiPadding": "啟用 SET ANSI_PADDING",
			"mssql.query.ansiWarnings": "啟用 SET ANSI_WARNINGS",
			"mssql.query.arithAbort": "啟用 SET ARITHABORT 選項",
			"mssql.query.cursorCloseOnCommit": "啟用 SET CURSOR_CLOSE_ON_COMMIT",
			"mssql.query.deadlockPriority": "啟用 SET DEADLOCK_PRIORITY 選項",
			"mssql.query.displayBitAsNumber": "BIT 資料行是否顯示為數字 (1 或 0)? 若為 False，BIT 資料行將會顯示為 'True' 或 'False'",
			"mssql.query.executionTimeout": "執行逾時為 0 表示無限等候 (不逾時)",
			"mssql.query.implicitTransactions": "啟用 SET IMPLICIT_TRANSACTIONS",
			"mssql.query.lockTimeout": "啟用 SET LOCK TIMEOUT 選項 (毫秒)",
			"mssql.query.maxXmlCharsToStore": "執行查詢之後要儲存的 XML 字元數目",
			"mssql.query.noCount": "啟用 SET NOCOUNT 選項",
			"mssql.query.noExec": "啟用 SET NOEXEC 選項",
			"mssql.query.parseOnly": "啟用 SET PARSEONLY 選項",
			"mssql.query.queryGovernorCostLimit": "啟用 SET QUERY_GOVERNOR_COST_LIMIT",
			"mssql.query.quotedIdentifier": "啟用 SET QUOTED_IDENTIFIER",
			"mssql.query.setRowCount": "要在伺服器停止處理查詢前傳回的資料列數上限。",
			"mssql.query.statisticsIO": "啟用 SET STATISTICS IO 選項",
			"mssql.query.statisticsTime": "啟用 SET STATISTICS TIME 選項",
			"mssql.query.textSize": "SELECT 陳述式所傳回 text 與 Ntext 資料的大小上限",
			"mssql.query.transactionIsolationLevel": "啟用 SET TRANSACTION ISOLATION LEVEL 選項",
			"mssql.query.xactAbortOn": "啟用 SET XACT_ABORT ON 選項",
			"mssql.tracingLevel": "[選用] 後端服務的記錄層級。每當 Azure Data Studio 啟動，或是檔案已經有附加至該檔案的記錄項目時，Azure Data Studio 都會產生檔案名稱。如需清除舊記錄檔，請查看 logRetentionMinutes 和 logFilesRemovalLimit 設定。預設 tracingLevel 不會記錄太多項目。變更詳細資訊可能會導致大量記錄和記錄的磁碟空間需求。錯誤包含嚴重，警告包含錯誤，資訊包含警告而詳細資訊包含資訊",
			"mssqlCluster.copyPath": "複製路徑",
			"mssqlCluster.deleteFiles": "刪除",
			"mssqlCluster.manageAccess": "管理存取權",
			"mssqlCluster.mkdir": "新增目錄",
			"mssqlCluster.previewFile": "預覽",
			"mssqlCluster.saveFile": "儲存",
			"mssqlCluster.uploadFiles": "上傳檔案",
			"notebook.command.new": "新增 Notebook",
			"notebook.command.open": "開啟 Notebook",
			"objectsListProperties.name": "名稱",
			"onprem.databaseProperties.compatibilityLevel": "相容性層級",
			"onprem.databaseProperties.lastBackupDate": "上次資料庫備份",
			"onprem.databaseProperties.lastLogBackupDate": "上次記錄備份",
			"onprem.databaseProperties.owner": "擁有者",
			"onprem.databaseProperties.recoveryModel": "復原模式",
			"onprem.serverProperties.machineName": "電腦名稱",
			"onprem.serverProperties.osVersion": "作業系統版本",
			"onprem.serverProperties.serverEdition": "版本",
			"onprem.serverProperties.serverVersion": "版本",
			"tab.bigDataClusterDescription": "SQL Server 巨量資料叢集的工作和資訊",
			"title.bigDataCluster": "SQL Server 巨量資料叢集",
			"title.books": "Notebooks",
			"title.clearSearchServerResult": "搜尋: 清除搜尋伺服器結果",
			"title.configurePython": "為 Notebooks 設定 Python",
			"title.endpoints": "服務端點",
			"title.installPackages": "安裝套件",
			"title.newSparkJob": "新增 Spark 作業",
			"title.openClusterDashboard": "叢集\r\n儀表板",
			"title.openSparkHistory": "檢視 Spark 歷程記錄",
			"title.openYarnHistory": "檢視 Yarn 歷程記錄",
			"title.searchServers": "搜尋: 伺服器",
			"title.showLogFile": "顯示記錄檔",
			"title.submitSparkJob": "提交 Spark 作業",
			"title.tasks": "工作"
		}
	}
}